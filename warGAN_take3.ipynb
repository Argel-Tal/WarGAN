{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python385jvsc74a57bd0fd02e15c5e8f5ee6cdee280f4db237d56a650e119945c60bf91993c8f57ebb6a",
      "display_name": "Python 3.8.5 64-bit (conda)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    },
    "colab": {
      "name": "warGAN_take3.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvkgrkaeN3Fr"
      },
      "source": [
        "# GAN IMPLEMENTATION FROM COMMUNITY INQ28 MODELS\n",
        "- Code Author: Jack MacCormick\n",
        "- Instagram: argelpaints: https://www.instagram.com/argelpaints/\n",
        "- Done in partnership with 28MAG: https://28-mag.com/\n",
        "\n",
        "**GAN Training and Development Code:**\n",
        "\n",
        "This project is the use of GAN style Machine Learning algorithms to generate new images, based off the works of the Warhammer INQ28 community. These images are the dreamings of an abhorent AI system, who's task is to understand \"what is INQ28\" it knows not the world, it's surroundings, only those offered to it, and the endless void"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjdWA9soN_Nl",
        "outputId": "9831faac-a790-4fdb-f404-19ae7c2f8c1d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2XzmLphN3Fs"
      },
      "source": [
        "# import necessary packages\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import pylab\n",
        "import h5py\n",
        "\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "from numpy import expand_dims\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy.random import random\n",
        "from numpy.random import randint\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from tqdm import tqdm \n",
        "from IPython import display "
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0tR1JKEN3Ft"
      },
      "source": [
        "\"\"\"\n",
        "define the standalone discriminator model\n",
        "key value is the learning rate lr\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def define_discriminator(in_shape=(200,200,1)):\n",
        "\t# weight initialization\n",
        "\tinit = 'uniform'\n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        "\t# downsample to 100x100\n",
        "\tmodel.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, input_shape=in_shape))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# downsample to 50x50\n",
        "\tmodel.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# classifier\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# compile model\n",
        "\topt = Adam(lr=0.0001, beta_1=0.5)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFYvDa97N3Ft"
      },
      "source": [
        "def define_generator(latent_dim):\n",
        "\t# weight initialization\n",
        "\tinit = 'uniform'\n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        "\t# foundation for 50x50 image\n",
        "\tn_nodes = 256 * 50 * 50\n",
        "\tmodel.add(Dense(n_nodes, kernel_initializer=init, input_dim=latent_dim))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Reshape((50, 50, 256)))\n",
        "\t# upsample to 100x100\n",
        "\tmodel.add(Conv2DTranspose(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# upsample to 200x200\n",
        "\tmodel.add(Conv2DTranspose(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# output 28x28x1\n",
        "\tmodel.add(Conv2D(1, (7,7), activation='tanh', padding='same', kernel_initializer=init))\n",
        "\treturn model"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbo8AaESN3Fu"
      },
      "source": [
        "# define the combined generator and discriminator model, for updating the generator\n",
        "def define_gan(generator, discriminator):\n",
        "\t# make weights in the discriminator not trainable\n",
        "\tdiscriminator.trainable = False\n",
        "\t# connect them\n",
        "\tmodel = Sequential()\n",
        "\t# add generator\n",
        "\tmodel.add(generator)\n",
        "\t# add the discriminator\n",
        "\tmodel.add(discriminator)\n",
        "\t# compile model\n",
        "\topt = Adam(lr=0.0001, beta_1=0.7)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "\treturn model"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDcW9TnyN3Fu"
      },
      "source": [
        "# default values of standardised images\n",
        "preferred_width = 200\n",
        "preferred_height = 200"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFcQwtFrPkiA"
      },
      "source": [
        "pathSource = '/content/drive/MyDrive/BnWDrive'\n",
        "dir_list = os.listdir(pathSource)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xl3i_0GAOZJ_"
      },
      "source": [
        "\n",
        "\n",
        "images = []\n",
        "# for image in pathSource, convert them to BnW, save that to pathDest, then add standardised version to images[]\n",
        "for image in dir_list:\n",
        "    img = Image.open(pathSource+\"/\"+image)\n",
        "    imgArray = np.array(img) # int array of pixels\n",
        "    imgArray = imgArray.astype(float)/255 # standardise values to be 0:255\n",
        "    images.append(imgArray)\n"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "QAzoYSfVN3Fw",
        "outputId": "e3f47a4c-d71b-477b-dabc-4fc7aaecd7bd"
      },
      "source": [
        "# setting a param for proportion of data to keep for testing\n",
        "testingSize = int(len(dir_list)/5)\n",
        "\n",
        "X_testing = np.array(images[0:testingSize])\n",
        "X_training = np.array(images[testingSize:len(images)])\n",
        "\n",
        "\"\"\"\n",
        "# this is all diagnostic checks to ensuredata is passed correctly to training and testing splits\n",
        "\n",
        "# code:\n",
        "print(np.shape(X_testing)) \n",
        "print(X_testing[1]) # checking it's correctly put something into the testing variable\n",
        "print(np.shape(X_training))\n",
        "# end code\n",
        "\"\"\""
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n# this is all diagnostic checks to ensuredata is passed correctly to training and testing splits\\n\\n# code:\\nprint(np.shape(X_testing)) \\nprint(X_testing[1]) # checking it's correctly put something into the testing variable\\nprint(np.shape(X_training))\\n# end code\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV21XCFMN3Fw"
      },
      "source": [
        "# select real samples\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "\t# choose random instances\n",
        "\tix = randint(0, dataset.shape[0], n_samples)\n",
        "\t# select images\n",
        "\tX = dataset[ix]\n",
        "\t# generate class labels\n",
        "\ty = ones((n_samples, 1))\n",
        "\treturn X, y"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmw5tCJbN3Fw"
      },
      "source": [
        "# generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "\t# generate points in the latent space\n",
        "\tx_input = np.random.uniform(low=0.0, high=1.0, size=(latent_dim, n_samples))\n",
        "\t# reshape into a batch of inputs for the network\n",
        "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
        "\treturn x_input"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGzrSa3GN3Fx"
      },
      "source": [
        "# use the generator to generate n fake examples, with class labels\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "\t# generate points in latent space\n",
        "\tx_input = abs(generate_latent_points(latent_dim, n_samples))\n",
        "\t# predict outputs\n",
        "\tX = generator.predict(x_input)\n",
        "\t# create class labels\n",
        "\ty = zeros((n_samples, 1))\n",
        "\treturn X, y"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOzLxk6-N3Fx"
      },
      "source": [
        "\"\"\"\n",
        "trains the generator and discriminator parts of the GAN\n",
        "saves the net model to a .h5 file\n",
        "\"\"\"\n",
        "\n",
        "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs, n_batch):\n",
        "\t# calculate the number of batches per epoch\n",
        "\tbat_per_epo = int(dataset.shape[0] / n_batch)\n",
        "\t# calculate the total iterations based on batch and epoch\n",
        "\tn_steps = bat_per_epo * n_epochs\n",
        "\t# calculate the number of samples in half a batch\n",
        "\thalf_batch = int(n_batch / 2)\n",
        "\t# prepare lists for storing stats each iteration\n",
        "\td1_hist, d2_hist, g_hist, a1_hist, a2_hist = list(), list(), list(), list(), list()\n",
        "\t# manually enumerate epochs\n",
        "\tfor i in range(n_steps):\n",
        "\t\t# get randomly selected 'real' samples\n",
        "\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "\t\t# update discriminator model weights\n",
        "\t\td_loss1, d_acc1 = d_model.train_on_batch(X_real, y_real)\n",
        "\t\t# generate 'fake' examples\n",
        "\t\tX_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "\t\t# update discriminator model weights\n",
        "\t\td_loss2, d_acc2 = d_model.train_on_batch(X_fake, y_fake)\n",
        "\t\t# prepare points in latent space as input for the generator\n",
        "\t\tX_gan = generate_latent_points(latent_dim, n_batch)\n",
        "\t\t# create inverted labels for the fake samples\n",
        "\t\ty_gan = ones((n_batch, 1))\n",
        "\t\t# update the generator via the discriminator's error\n",
        "\t\tg_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "\t\t# summarize loss on this batch\n",
        "\t\tprint('>%d/%d, d1=%.3f, d2=%.3f g=%.3f, a1=%d, a2=%d' %\n",
        "\t\t\t(i+1, n_steps, d_loss1, d_loss2, g_loss, int(100*d_acc1), int(100*d_acc2)))\n",
        "\t\t# record history\n",
        "\t\td1_hist.append(d_loss1)\n",
        "\t\td2_hist.append(d_loss2)\n",
        "\t\tg_hist.append(g_loss)\n",
        "\t\ta1_hist.append(d_acc1)\n",
        "\t\ta2_hist.append(d_acc2)\n",
        "\t\tif (i%10==0): # save frequency, this should really be a smart value\n",
        "\t\t\tg_model.save('WARgenerator.h5')\t\t\n",
        "\tprint(\"finished training\")\n",
        "\t# this is the generator that can be called externally\n",
        "\tg_model.save('WARgenerator.h5') \n",
        "\t\"\"\"\n",
        "\tSave is also embed this within the loop every so many itterations\n",
        "\tso something is saved/retained if user needs to abort while long training processes are occuring or if something fails, if the kernel or local machine crashes or if local machine looses power\n",
        "\t\"\"\""
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE2TwB57N3Fx"
      },
      "source": [
        "\"\"\"\n",
        "set up the data into something the GAN can use in training\n",
        "\"\"\"\n",
        "\n",
        "X_train=np.reshape(X_training,(X_training.shape[0], X_training.shape[1],X_training.shape[2],1))"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7NTO10VN3Fy",
        "outputId": "90e7d030-5c37-4bdf-e95c-08c21123c863"
      },
      "source": [
        "\"\"\"\n",
        "set up for training and training call\n",
        "this can take some time depending on number of epochs\n",
        "recommend running on a GPU\n",
        "\"\"\"\n",
        "\n",
        "# training params\n",
        "latent_dim = 50 # size of the latent space\n",
        "n_epochs = 100 # number of \"generations\"\n",
        "n_batch = 15 # batch (of images) size\n",
        "# create the discriminator\n",
        "discriminator = define_discriminator()\n",
        "# create the generator\n",
        "generator = define_generator(latent_dim)\n",
        "# create the gan\n",
        "gan_model = define_gan(generator, discriminator)\n",
        "# load image data\n",
        "dataset = X_train\n",
        "\n",
        "# train model\n",
        "train(generator, discriminator, gan_model, dataset, latent_dim, n_epochs, n_batch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">1/1000, d1=0.717, d2=0.708 g=0.684, a1=0, a2=0\n",
            ">2/1000, d1=0.471, d2=0.798 g=0.605, a1=100, a2=0\n",
            ">3/1000, d1=0.314, d2=0.944 g=0.507, a1=100, a2=0\n",
            ">4/1000, d1=0.237, d2=1.122 g=0.446, a1=100, a2=0\n",
            ">5/1000, d1=0.244, d2=1.181 g=0.428, a1=100, a2=0\n",
            ">6/1000, d1=0.270, d2=1.177 g=0.453, a1=100, a2=0\n",
            ">7/1000, d1=0.326, d2=1.137 g=0.506, a1=100, a2=0\n",
            ">8/1000, d1=0.403, d2=1.011 g=0.563, a1=100, a2=0\n",
            ">9/1000, d1=0.498, d2=0.962 g=0.602, a1=100, a2=0\n",
            ">10/1000, d1=0.559, d2=0.925 g=0.617, a1=100, a2=0\n",
            ">11/1000, d1=0.615, d2=0.916 g=0.606, a1=100, a2=0\n",
            ">12/1000, d1=0.636, d2=0.927 g=0.586, a1=100, a2=0\n",
            ">13/1000, d1=0.642, d2=0.926 g=0.579, a1=85, a2=0\n",
            ">14/1000, d1=0.618, d2=0.906 g=0.595, a1=100, a2=0\n",
            ">15/1000, d1=0.610, d2=0.873 g=0.624, a1=100, a2=0\n",
            ">16/1000, d1=0.547, d2=0.822 g=0.685, a1=100, a2=0\n",
            ">17/1000, d1=0.498, d2=0.786 g=0.715, a1=100, a2=0\n",
            ">18/1000, d1=0.479, d2=0.850 g=0.682, a1=100, a2=0\n",
            ">19/1000, d1=0.440, d2=0.964 g=0.603, a1=100, a2=0\n",
            ">20/1000, d1=0.485, d2=1.081 g=0.497, a1=100, a2=0\n",
            ">21/1000, d1=0.512, d2=1.171 g=0.445, a1=100, a2=0\n",
            ">22/1000, d1=0.509, d2=1.196 g=0.449, a1=100, a2=0\n",
            ">23/1000, d1=0.520, d2=1.114 g=0.498, a1=100, a2=0\n",
            ">24/1000, d1=0.560, d2=0.992 g=0.571, a1=100, a2=0\n",
            ">25/1000, d1=0.553, d2=0.933 g=0.618, a1=100, a2=0\n",
            ">26/1000, d1=0.468, d2=0.928 g=0.646, a1=100, a2=0\n",
            ">27/1000, d1=0.438, d2=0.948 g=0.611, a1=100, a2=0\n",
            ">28/1000, d1=0.469, d2=1.047 g=0.534, a1=100, a2=0\n",
            ">29/1000, d1=0.462, d2=1.093 g=0.486, a1=100, a2=0\n",
            ">30/1000, d1=0.460, d2=1.139 g=0.486, a1=100, a2=0\n",
            ">31/1000, d1=0.465, d2=1.132 g=0.480, a1=100, a2=0\n",
            ">32/1000, d1=0.442, d2=1.099 g=0.502, a1=100, a2=0\n",
            ">33/1000, d1=0.504, d2=1.085 g=0.511, a1=100, a2=0\n",
            ">34/1000, d1=0.509, d2=1.091 g=0.504, a1=100, a2=0\n",
            ">35/1000, d1=0.480, d2=1.068 g=0.520, a1=100, a2=0\n",
            ">36/1000, d1=0.524, d2=1.038 g=0.541, a1=100, a2=0\n",
            ">37/1000, d1=0.556, d2=1.024 g=0.544, a1=100, a2=0\n",
            ">38/1000, d1=0.556, d2=1.031 g=0.550, a1=100, a2=0\n",
            ">39/1000, d1=0.579, d2=1.018 g=0.560, a1=100, a2=0\n",
            ">40/1000, d1=0.554, d2=1.044 g=0.554, a1=100, a2=0\n",
            ">41/1000, d1=0.562, d2=1.043 g=0.562, a1=100, a2=0\n",
            ">42/1000, d1=0.551, d2=1.012 g=0.571, a1=100, a2=0\n",
            ">43/1000, d1=0.587, d2=1.010 g=0.574, a1=100, a2=0\n",
            ">44/1000, d1=0.603, d2=0.992 g=0.594, a1=100, a2=0\n",
            ">45/1000, d1=0.625, d2=0.946 g=0.607, a1=100, a2=0\n",
            ">46/1000, d1=0.644, d2=0.917 g=0.619, a1=100, a2=0\n",
            ">47/1000, d1=0.648, d2=0.891 g=0.628, a1=100, a2=0\n",
            ">48/1000, d1=0.672, d2=0.878 g=0.645, a1=85, a2=0\n",
            ">49/1000, d1=0.654, d2=0.861 g=0.652, a1=85, a2=0\n",
            ">50/1000, d1=0.649, d2=0.858 g=0.657, a1=85, a2=0\n",
            ">51/1000, d1=0.645, d2=0.837 g=0.673, a1=100, a2=0\n",
            ">52/1000, d1=0.689, d2=0.822 g=0.686, a1=57, a2=0\n",
            ">53/1000, d1=0.667, d2=0.807 g=0.689, a1=85, a2=0\n",
            ">54/1000, d1=0.684, d2=0.808 g=0.686, a1=71, a2=0\n",
            ">55/1000, d1=0.690, d2=0.801 g=0.684, a1=71, a2=0\n",
            ">56/1000, d1=0.721, d2=0.798 g=0.684, a1=14, a2=0\n",
            ">57/1000, d1=0.718, d2=0.790 g=0.689, a1=14, a2=0\n",
            ">58/1000, d1=0.738, d2=0.778 g=0.696, a1=0, a2=0\n",
            ">59/1000, d1=0.746, d2=0.774 g=0.691, a1=0, a2=0\n",
            ">60/1000, d1=0.739, d2=0.773 g=0.687, a1=0, a2=0\n",
            ">61/1000, d1=0.743, d2=0.768 g=0.691, a1=0, a2=0\n",
            ">62/1000, d1=0.738, d2=0.758 g=0.695, a1=0, a2=0\n",
            ">63/1000, d1=0.751, d2=0.754 g=0.696, a1=0, a2=0\n",
            ">64/1000, d1=0.745, d2=0.748 g=0.701, a1=0, a2=0\n",
            ">65/1000, d1=0.752, d2=0.743 g=0.702, a1=0, a2=0\n",
            ">66/1000, d1=0.755, d2=0.741 g=0.701, a1=0, a2=0\n",
            ">67/1000, d1=0.753, d2=0.742 g=0.699, a1=0, a2=0\n",
            ">68/1000, d1=0.757, d2=0.745 g=0.693, a1=0, a2=0\n",
            ">69/1000, d1=0.753, d2=0.754 g=0.685, a1=0, a2=0\n",
            ">70/1000, d1=0.742, d2=0.761 g=0.676, a1=0, a2=0\n",
            ">71/1000, d1=0.740, d2=0.768 g=0.671, a1=0, a2=0\n",
            ">72/1000, d1=0.733, d2=0.775 g=0.662, a1=0, a2=0\n",
            ">73/1000, d1=0.721, d2=0.781 g=0.660, a1=0, a2=0\n",
            ">74/1000, d1=0.725, d2=0.780 g=0.666, a1=0, a2=0\n",
            ">75/1000, d1=0.728, d2=0.787 g=0.655, a1=0, a2=0\n",
            ">76/1000, d1=0.714, d2=0.797 g=0.655, a1=0, a2=0\n",
            ">77/1000, d1=0.716, d2=0.793 g=0.646, a1=0, a2=0\n",
            ">78/1000, d1=0.701, d2=0.799 g=0.641, a1=14, a2=0\n",
            ">79/1000, d1=0.692, d2=0.806 g=0.634, a1=71, a2=0\n",
            ">80/1000, d1=0.681, d2=0.805 g=0.640, a1=85, a2=0\n",
            ">81/1000, d1=0.668, d2=0.809 g=0.643, a1=100, a2=0\n",
            ">82/1000, d1=0.665, d2=0.799 g=0.652, a1=100, a2=0\n",
            ">83/1000, d1=0.671, d2=0.792 g=0.665, a1=100, a2=0\n",
            ">84/1000, d1=0.671, d2=0.789 g=0.657, a1=100, a2=0\n",
            ">85/1000, d1=0.655, d2=0.791 g=0.668, a1=100, a2=0\n",
            ">86/1000, d1=0.655, d2=0.784 g=0.667, a1=100, a2=0\n",
            ">87/1000, d1=0.659, d2=0.786 g=0.653, a1=100, a2=0\n",
            ">88/1000, d1=0.654, d2=0.788 g=0.663, a1=85, a2=0\n",
            ">89/1000, d1=0.649, d2=0.782 g=0.666, a1=100, a2=0\n",
            ">90/1000, d1=0.667, d2=0.777 g=0.671, a1=100, a2=0\n",
            ">91/1000, d1=0.670, d2=0.767 g=0.677, a1=71, a2=0\n",
            ">92/1000, d1=0.676, d2=0.762 g=0.681, a1=71, a2=0\n",
            ">93/1000, d1=0.669, d2=0.760 g=0.680, a1=85, a2=0\n",
            ">94/1000, d1=0.682, d2=0.765 g=0.667, a1=100, a2=0\n",
            ">95/1000, d1=0.659, d2=0.767 g=0.668, a1=100, a2=0\n",
            ">96/1000, d1=0.676, d2=0.758 g=0.686, a1=85, a2=0\n",
            ">97/1000, d1=0.698, d2=0.754 g=0.679, a1=42, a2=0\n",
            ">98/1000, d1=0.687, d2=0.755 g=0.678, a1=57, a2=0\n",
            ">99/1000, d1=0.677, d2=0.755 g=0.675, a1=85, a2=0\n",
            ">100/1000, d1=0.677, d2=0.756 g=0.681, a1=71, a2=0\n",
            ">101/1000, d1=0.682, d2=0.750 g=0.685, a1=85, a2=0\n",
            ">102/1000, d1=0.673, d2=0.750 g=0.680, a1=100, a2=0\n",
            ">103/1000, d1=0.678, d2=0.752 g=0.685, a1=85, a2=0\n",
            ">104/1000, d1=0.687, d2=0.746 g=0.688, a1=57, a2=0\n",
            ">105/1000, d1=0.689, d2=0.736 g=0.701, a1=57, a2=0\n",
            ">106/1000, d1=0.705, d2=0.738 g=0.689, a1=28, a2=0\n",
            ">107/1000, d1=0.697, d2=0.734 g=0.699, a1=42, a2=0\n",
            ">108/1000, d1=0.694, d2=0.728 g=0.705, a1=42, a2=0\n",
            ">109/1000, d1=0.688, d2=0.727 g=0.710, a1=71, a2=0\n",
            ">110/1000, d1=0.696, d2=0.730 g=0.702, a1=71, a2=0\n",
            ">111/1000, d1=0.697, d2=0.734 g=0.700, a1=57, a2=0\n",
            ">112/1000, d1=0.695, d2=0.738 g=0.696, a1=57, a2=0\n",
            ">113/1000, d1=0.684, d2=0.736 g=0.699, a1=71, a2=0\n",
            ">114/1000, d1=0.699, d2=0.733 g=0.699, a1=42, a2=0\n",
            ">115/1000, d1=0.689, d2=0.729 g=0.706, a1=57, a2=0\n",
            ">116/1000, d1=0.695, d2=0.729 g=0.706, a1=42, a2=0\n",
            ">117/1000, d1=0.693, d2=0.727 g=0.710, a1=42, a2=0\n",
            ">118/1000, d1=0.687, d2=0.731 g=0.700, a1=85, a2=0\n",
            ">119/1000, d1=0.682, d2=0.737 g=0.696, a1=71, a2=0\n",
            ">120/1000, d1=0.695, d2=0.734 g=0.697, a1=57, a2=0\n",
            ">121/1000, d1=0.681, d2=0.731 g=0.698, a1=85, a2=0\n",
            ">122/1000, d1=0.688, d2=0.734 g=0.700, a1=71, a2=0\n",
            ">123/1000, d1=0.697, d2=0.733 g=0.698, a1=42, a2=0\n",
            ">124/1000, d1=0.687, d2=0.734 g=0.694, a1=57, a2=0\n",
            ">125/1000, d1=0.699, d2=0.734 g=0.692, a1=42, a2=0\n",
            ">126/1000, d1=0.700, d2=0.733 g=0.694, a1=28, a2=0\n",
            ">127/1000, d1=0.695, d2=0.729 g=0.696, a1=57, a2=0\n",
            ">128/1000, d1=0.697, d2=0.724 g=0.705, a1=42, a2=0\n",
            ">129/1000, d1=0.709, d2=0.720 g=0.706, a1=14, a2=0\n",
            ">130/1000, d1=0.700, d2=0.719 g=0.707, a1=42, a2=0\n",
            ">131/1000, d1=0.695, d2=0.720 g=0.706, a1=42, a2=0\n",
            ">132/1000, d1=0.701, d2=0.726 g=0.697, a1=42, a2=0\n",
            ">133/1000, d1=0.688, d2=0.730 g=0.698, a1=85, a2=0\n",
            ">134/1000, d1=0.684, d2=0.729 g=0.698, a1=85, a2=0\n",
            ">135/1000, d1=0.691, d2=0.728 g=0.699, a1=57, a2=0\n",
            ">136/1000, d1=0.683, d2=0.729 g=0.700, a1=71, a2=0\n",
            ">137/1000, d1=0.696, d2=0.728 g=0.698, a1=42, a2=0\n",
            ">138/1000, d1=0.689, d2=0.727 g=0.704, a1=57, a2=0\n",
            ">139/1000, d1=0.693, d2=0.724 g=0.708, a1=42, a2=0\n",
            ">140/1000, d1=0.698, d2=0.719 g=0.711, a1=42, a2=0\n",
            ">141/1000, d1=0.706, d2=0.721 g=0.707, a1=28, a2=0\n",
            ">142/1000, d1=0.695, d2=0.721 g=0.702, a1=42, a2=0\n",
            ">143/1000, d1=0.692, d2=0.719 g=0.707, a1=28, a2=0\n",
            ">144/1000, d1=0.699, d2=0.715 g=0.714, a1=14, a2=0\n",
            ">145/1000, d1=0.712, d2=0.714 g=0.713, a1=0, a2=0\n",
            ">146/1000, d1=0.705, d2=0.716 g=0.703, a1=0, a2=0\n",
            ">147/1000, d1=0.704, d2=0.717 g=0.707, a1=0, a2=0\n",
            ">148/1000, d1=0.703, d2=0.712 g=0.712, a1=14, a2=0\n",
            ">149/1000, d1=0.705, d2=0.708 g=0.714, a1=14, a2=0\n",
            ">150/1000, d1=0.717, d2=0.705 g=0.718, a1=0, a2=0\n",
            ">151/1000, d1=0.710, d2=0.705 g=0.716, a1=0, a2=0\n",
            ">152/1000, d1=0.715, d2=0.705 g=0.721, a1=0, a2=0\n",
            ">153/1000, d1=0.719, d2=0.710 g=0.709, a1=0, a2=0\n",
            ">154/1000, d1=0.703, d2=0.712 g=0.705, a1=0, a2=0\n",
            ">155/1000, d1=0.713, d2=0.710 g=0.709, a1=0, a2=0\n",
            ">156/1000, d1=0.704, d2=0.707 g=0.713, a1=14, a2=0\n",
            ">157/1000, d1=0.704, d2=0.707 g=0.712, a1=28, a2=0\n",
            ">158/1000, d1=0.709, d2=0.710 g=0.709, a1=0, a2=0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNtZAHU3N3Fy",
        "outputId": "f7330681-4700-49c3-eea4-63d304bb7d48"
      },
      "source": [
        "\"\"\"\n",
        "getting the model to draw something,\n",
        "this can be done seperately, if put in another file\n",
        "\"\"\"\n",
        "\n",
        "model = load_model('WARgenerator.h5', compile = False)\n",
        "# generate images\n",
        "latent_points = generate_latent_points(latent_dim, 1)\n",
        " # has quite the think about it\n",
        "predictionInstance = model.predict(latent_points)\n",
        "print(\"done thinking\")"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done thinking\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKqyPOEFN3Fy",
        "outputId": "1e7f832f-1044-4a2f-b891-f4c35b00986a"
      },
      "source": [
        "\"\"\"\n",
        "Training of existing model file:\n",
        "May not always want to run this cell\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "n_epochs = 50\n",
        "n_batch = 15\n",
        "train(model, discriminator, gan_model, dataset, latent_dim, n_epochs, n_batch)\n",
        "\"\"\"\n",
        "()"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zxxqpY4N3Fz",
        "outputId": "f390896d-dea1-4e11-c8c7-ee5b34c8856f"
      },
      "source": [
        "\"\"\"\n",
        "getting the prediction directly from generator\n",
        "functionally the same as prediction instance\n",
        "\"\"\"\n",
        "\n",
        "xout = generate_fake_samples(generator, latent_dim, n_samples = 1)[0]\n",
        "# predictionInstance = model.predict(latent_points)\n",
        "# convert floats from ranges 0:1 to 0:255, so they can be blackness values in an image\n",
        "xout = predictionInstance*255 \n",
        "# print(xout) # this is diagnostic\n",
        "# np.shape(xout) # this is diagnostic\n",
        "flatXOut = xout.flatten()  \n",
        "# print(len(flatXOut)) # should be 40,000 # this is diagnostic\n",
        "arr_2d = np.reshape(flatXOut, (200, 200))\n",
        "# convert float array to ints\n",
        "array_int = abs(np.array(arr_2d, dtype='int')) \n",
        "print(np.shape(array_int)) # this is diagnostic\n",
        "array_int # this is diagnostic\n",
        "\n"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(200, 200)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[220, 246, 225, ..., 249, 251, 246],\n",
              "       [246, 243, 238, ..., 242, 249, 247],\n",
              "       [243, 248, 240, ..., 243, 249, 246],\n",
              "       ...,\n",
              "       [239, 240, 246, ..., 220, 248, 244],\n",
              "       [239, 240, 228, ..., 244, 250, 249],\n",
              "       [216, 234, 237, ..., 243, 249, 246]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwjCHdy_N3Fz",
        "outputId": "d4845cd8-9393-4b32-8a94-a7a8b478a647"
      },
      "source": [
        "'''\n",
        "\"\"\"\n",
        "getting the prediction into something useful\n",
        "\"\"\"\n",
        "\n",
        "# convert floats from ranges 0:1 to 0:255, so they can be blackness values in an image\n",
        "xout = predictionInstance*255 \n",
        "# print(xout) # this is diagnostic\n",
        "# np.shape(xout) # this is diagnostic\n",
        "flatXOut = xout.flatten()  \n",
        "# print(len(flatXOut)) # should be 40,000 # this is diagnostic\n",
        "arr_2d = np.reshape(flatXOut, (200, 200))\n",
        "# convert float array to ints\n",
        "array_int = abs(np.array(arr_2d, dtype='int')) \n",
        "# print(np.shape(array_int)) # this is diagnostic\n",
        "# array_int # this is diagnostic\n",
        "\n",
        "'''\n",
        "()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "M8MAwV3CN3Fz",
        "outputId": "03707b26-2cf4-4208-af87-e1724030fdc5"
      },
      "source": [
        "\"\"\"\n",
        "draw the image of the output array\n",
        "\"\"\"\n",
        "\n",
        "img = Image.fromarray(array_int.astype(np.uint8))\n",
        "\n",
        "\"\"\"\n",
        "diagnostic check of the output image\n",
        "\n",
        "# code:\n",
        "print(\"Format: {0}\\nSize: {1}\\nMode: {2}\".format(img.format, \n",
        "    img.size, img.mode)) \n",
        "# end code\n",
        "\"\"\"\n"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ndiagnostic check of the output image\\n\\n# code:\\nprint(\"Format: {0}\\nSize: {1}\\nMode: {2}\".format(img.format, \\n    img.size, img.mode)) \\n# end code\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu834qShN3Fz"
      },
      "source": [
        "\"\"\"\n",
        "convert the image file to a recognisable and portable format\n",
        "write out the image file to somewhere in the local machine\n",
        "\"\"\"\n",
        "\n",
        "pathOut = '/content/drive/MyDrive/BnWOut'\n",
        "imgRGB = img.convert(mode=\"RGB\")\n",
        "imgRGB.save(pathOut+\"/dreamParamTest5.jpg\")"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vs4ar1aGN3F0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}