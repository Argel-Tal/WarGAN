{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN IMPLEMENTATION FROM COMMUNITY INQ28 MODELS\n",
    "- Code Author: Jack MacCormick\n",
    "- Instagram: argelpaints: https://www.instagram.com/argelpaints/\n",
    "- Done in partnership with 28MAG: https://28-mag.com/\n",
    "\n",
    "**GAN Training and Development Code:**\n",
    "\n",
    "This project is the use of GAN style Machine Learning algorithms to generate new images, based off the works of the Warhammer INQ28 community. These images are the dreamings of an abhorent AI system, who's task is to understand \"what is INQ28\" it knows not the world, it's surroundings, only those offered to it, and the endless void"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import os\n",
    "'''\n",
    "should be able to delete these redundant packages\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pylab\n",
    "import h5py\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import random\n",
    "from numpy.random import randint\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tqdm import tqdm \n",
    "from IPython import display "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "define the standalone discriminator model\n",
    "key value is the learning rate lr\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def define_discriminator(in_shape=(200,200,1)):\n",
    "\t# weight initialization\n",
    "\tinit = 'uniform'\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\t# downsample to 100x100\n",
    "\tmodel.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, input_shape=in_shape))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# downsample to 50x50\n",
    "\tmodel.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# classifier\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# compile model\n",
    "\topt = Adam(lr=0.0001, beta_1=0.5)\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_generator(latent_dim):\n",
    "\t# weight initialization\n",
    "\tinit = 'uniform'\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\t# foundation for 50x50 image\n",
    "\tn_nodes = 256 * 50 * 50\n",
    "\tmodel.add(Dense(n_nodes, kernel_initializer=init, input_dim=latent_dim))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\tmodel.add(Reshape((50, 50, 256)))\n",
    "\t# upsample to 100x100\n",
    "\tmodel.add(Conv2DTranspose(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# upsample to 200x200\n",
    "\tmodel.add(Conv2DTranspose(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# output 28x28x1\n",
    "\tmodel.add(Conv2D(1, (7,7), activation='tanh', padding='same', kernel_initializer=init))\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(generator, discriminator):\n",
    "\t# make weights in the discriminator not trainable\n",
    "\tdiscriminator.trainable = False\n",
    "\t# connect them\n",
    "\tmodel = Sequential()\n",
    "\t# add generator\n",
    "\tmodel.add(generator)\n",
    "\t# add the discriminator\n",
    "\tmodel.add(discriminator)\n",
    "\t# compile model\n",
    "\topt = Adam(lr=0.00015, beta_1=0.7)\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default values of standardised images\n",
    "preferred_width = 200\n",
    "preferred_height = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to take images from and to save to (after transformation to BnW)\n",
    "pathSource = \"C:\\\\Users\\\\DataSci\\\\Desktop\\\\DS_Testing\\\\warGAN\\\\igTest\"\n",
    "pathDest = \"C:\\\\Users\\\\DataSci\\\\Desktop\\\\DS_Testing\\\\warGAN\\\\BnWImages\"\n",
    "\n",
    "# list all objects in pathSource\n",
    "dir_list = os.listdir(pathSource)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n# diagnostic checks of images, checking shape and values look correct\\n\\n# code\\nprint(np.shape(images))\\nprint(images[0])\\nprint(np.shape(images[0]))\\n# end code\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "\"\"\"\n",
    "read in images from local machine\n",
    "create list to contain all standardised images;\n",
    "    values [0:1] for ML, instead of [0:255] for colour channels\n",
    "for image in pathSource:\n",
    "    convert them to BnW\n",
    "    save that BnW image to pathDest\n",
    "    then add standardised version to images[]\n",
    "\"\"\"\n",
    "\n",
    "images = []\n",
    "# for image in pathSource, convert them to BnW, save that to pathDest, then add standardised version to images[]\n",
    "for image in dir_list:\n",
    "    img = Image.open(pathSource+\"\\\\\"+image).convert('L').resize((preferred_width, preferred_height), Image.ANTIALIAS)\n",
    "    # img.show()\n",
    "    imgArray = np.array(img) # int array of pixels\n",
    "    imgArray = imgArray.astype(float)/255 # standardise values to be 0:255\n",
    "    images.append(imgArray)\n",
    "    img.save(pathDest+\"\\\\BnW\"+image, \"JPEG\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# diagnostic checks of images, checking shape and values look correct\n",
    "\n",
    "# code\n",
    "print(np.shape(images))\n",
    "print(images[0])\n",
    "print(np.shape(images[0]))\n",
    "# end code\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"\\n# this is all diagnostic checks to ensuredata is passed correctly to training and testing splits\\n\\n# code:\\nprint(np.shape(X_testing)) \\nprint(X_testing[1]) # checking it's correctly put something into the testing variable\\nprint(np.shape(X_training))\\n# end code\\n\""
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# setting a param for proportion of data to keep for testing\n",
    "testingSize = int(len(dir_list)/5)\n",
    "\n",
    "X_testing = np.array(images[0:testingSize])\n",
    "X_training = np.array(images[testingSize:len(images)])\n",
    "\n",
    "\"\"\"\n",
    "# this is all diagnostic checks to ensuredata is passed correctly to training and testing splits\n",
    "\n",
    "# code:\n",
    "print(np.shape(X_testing)) \n",
    "print(X_testing[1]) # checking it's correctly put something into the testing variable\n",
    "print(np.shape(X_training))\n",
    "# end code\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "\t# choose random instances\n",
    "\tix = randint(0, dataset.shape[0], n_samples)\n",
    "\t# select images\n",
    "\tX = dataset[ix]\n",
    "\t# generate class labels\n",
    "\ty = ones((n_samples, 1))\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "\t# generate points in the latent space\n",
    "\tx_input = np.random.uniform(low=0.0, high=1.0, size=(latent_dim, n_samples))\n",
    "\t# reshape into a batch of inputs for the network\n",
    "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
    "\treturn x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "\t# generate points in latent space\n",
    "\tx_input = abs(generate_latent_points(latent_dim, n_samples))\n",
    "\t# predict outputs\n",
    "\tX = generator.predict(x_input)\n",
    "\t# create class labels\n",
    "\ty = zeros((n_samples, 1))\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "trains the generator and discriminator parts of the GAN\n",
    "saves the net model to a .h5 file\n",
    "\"\"\"\n",
    "\n",
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs, n_batch):\n",
    "\t# calculate the number of batches per epoch\n",
    "\tbat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "\t# calculate the total iterations based on batch and epoch\n",
    "\tn_steps = bat_per_epo * n_epochs\n",
    "\t# calculate the number of samples in half a batch\n",
    "\thalf_batch = int(n_batch / 2)\n",
    "\t# prepare lists for storing stats each iteration\n",
    "\td1_hist, d2_hist, g_hist, a1_hist, a2_hist = list(), list(), list(), list(), list()\n",
    "\t# manually enumerate epochs\n",
    "\tfor i in range(n_steps):\n",
    "\t\t# get randomly selected 'real' samples\n",
    "\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "\t\t# update discriminator model weights\n",
    "\t\td_loss1, d_acc1 = d_model.train_on_batch(X_real, y_real)\n",
    "\t\t# generate 'fake' examples\n",
    "\t\tX_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "\t\t# update discriminator model weights\n",
    "\t\td_loss2, d_acc2 = d_model.train_on_batch(X_fake, y_fake)\n",
    "\t\t# prepare points in latent space as input for the generator\n",
    "\t\tX_gan = generate_latent_points(latent_dim, n_batch)\n",
    "\t\t# create inverted labels for the fake samples\n",
    "\t\ty_gan = ones((n_batch, 1))\n",
    "\t\t# update the generator via the discriminator's error\n",
    "\t\tg_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "\t\t# summarize loss on this batch\n",
    "\t\tprint('>%d/%d, d1=%.3f, d2=%.3f g=%.3f, a1=%d, a2=%d' %\n",
    "\t\t\t(i+1, n_steps, d_loss1, d_loss2, g_loss, int(100*d_acc1), int(100*d_acc2)))\n",
    "\t\t# record history\n",
    "\t\td1_hist.append(d_loss1)\n",
    "\t\td2_hist.append(d_loss2)\n",
    "\t\tg_hist.append(g_loss)\n",
    "\t\ta1_hist.append(d_acc1)\n",
    "\t\ta2_hist.append(d_acc2)\n",
    "\t\tif (i%10==0): # save frequency, this should really be a smart value\n",
    "\t\t\tg_model.save('WARgenerator.h5')\t\t\n",
    "\tprint(\"finished training\")\n",
    "\t# this is the generator that can be called externally\n",
    "\tg_model.save('WARgenerator.h5') \n",
    "\t\"\"\"\n",
    "\tSave is also embed this within the loop every so many itterations\n",
    "\tso something is saved/retained if user needs to abort while long training processes are occuring or if something fails, if the kernel or local machine crashes or if local machine looses power\n",
    "\t\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "set up the data into something the GAN can use in training\n",
    "\"\"\"\n",
    "\n",
    "X_train=np.reshape(X_training,(X_training.shape[0], X_training.shape[1],X_training.shape[2],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">1/500, d1=0.722, d2=0.714 g=0.678, a1=0, a2=0\n",
      ">2/500, d1=0.421, d2=0.895 g=0.535, a1=100, a2=0\n",
      ">3/500, d1=0.305, d2=1.140 g=0.417, a1=100, a2=0\n",
      ">4/500, d1=0.265, d2=1.318 g=0.397, a1=100, a2=0\n",
      ">5/500, d1=0.330, d2=1.249 g=0.430, a1=100, a2=0\n",
      ">6/500, d1=0.416, d2=1.135 g=0.500, a1=100, a2=0\n",
      ">7/500, d1=0.517, d2=0.979 g=0.568, a1=100, a2=0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "set up for training and training call\n",
    "this can take some time depending on number of epochs\n",
    "recommend running on a GPU\n",
    "\"\"\"\n",
    "\n",
    "# training params\n",
    "latent_dim = 50 # size of the latent space\n",
    "n_epochs = 50 # number of \"generations\"\n",
    "n_batch = 15 # batch (of images) size\n",
    "# create the discriminator\n",
    "discriminator = define_discriminator()\n",
    "# create the generator\n",
    "generator = define_generator(latent_dim)\n",
    "# create the gan\n",
    "gan_model = define_gan(generator, discriminator)\n",
    "# load image data\n",
    "dataset = X_train\n",
    "\n",
    "# train model\n",
    "train(generator, discriminator, gan_model, dataset, latent_dim, n_epochs, n_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "done thinking\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "getting the model to draw something,\n",
    "this can be done seperately, if put in another file\n",
    "\"\"\"\n",
    "\n",
    "model = load_model('WARgenerator.h5', compile = False)\n",
    "# generate images\n",
    "latent_points = generate_latent_points(latent_dim, 1)\n",
    " # has quite the think about it\n",
    "predictionInstance = model.predict(latent_points)\n",
    "print(\"done thinking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">1/90, d1=0.016, d2=1.850 g=0.613, a1=100, a2=0\n",
      ">2/90, d1=0.061, d2=0.488 g=1.054, a1=100, a2=100\n",
      ">3/90, d1=0.190, d2=0.164 g=0.841, a1=100, a2=100\n",
      ">4/90, d1=0.251, d2=0.117 g=0.447, a1=100, a2=100\n",
      ">5/90, d1=0.180, d2=0.115 g=0.270, a1=100, a2=100\n",
      ">6/90, d1=0.111, d2=0.099 g=0.162, a1=100, a2=100\n",
      ">7/90, d1=0.081, d2=0.084 g=0.131, a1=100, a2=100\n",
      ">8/90, d1=0.091, d2=0.071 g=0.099, a1=100, a2=100\n",
      ">9/90, d1=0.079, d2=0.061 g=0.067, a1=100, a2=100\n",
      ">10/90, d1=0.043, d2=0.056 g=0.052, a1=100, a2=100\n",
      ">11/90, d1=0.065, d2=0.049 g=0.043, a1=100, a2=100\n",
      ">12/90, d1=0.029, d2=0.047 g=0.043, a1=100, a2=100\n",
      ">13/90, d1=0.039, d2=0.039 g=0.034, a1=100, a2=100\n",
      ">14/90, d1=0.042, d2=0.039 g=0.030, a1=100, a2=100\n",
      ">15/90, d1=0.088, d2=0.037 g=0.021, a1=100, a2=100\n",
      ">16/90, d1=0.053, d2=0.037 g=0.020, a1=100, a2=100\n",
      ">17/90, d1=0.041, d2=0.035 g=0.015, a1=100, a2=100\n",
      ">18/90, d1=0.022, d2=0.033 g=0.014, a1=100, a2=100\n",
      ">19/90, d1=0.048, d2=0.029 g=0.011, a1=100, a2=100\n",
      ">20/90, d1=0.042, d2=0.029 g=0.011, a1=100, a2=100\n",
      ">21/90, d1=0.015, d2=0.027 g=0.009, a1=100, a2=100\n",
      ">22/90, d1=0.013, d2=0.025 g=0.010, a1=100, a2=100\n",
      ">23/90, d1=0.028, d2=0.023 g=0.008, a1=100, a2=100\n",
      ">24/90, d1=0.017, d2=0.021 g=0.009, a1=100, a2=100\n",
      ">25/90, d1=0.008, d2=0.018 g=0.009, a1=100, a2=100\n",
      ">26/90, d1=0.014, d2=0.018 g=0.007, a1=100, a2=100\n",
      ">27/90, d1=0.032, d2=0.018 g=0.008, a1=100, a2=100\n",
      ">28/90, d1=0.017, d2=0.017 g=0.005, a1=100, a2=100\n",
      ">29/90, d1=0.007, d2=0.017 g=0.006, a1=100, a2=100\n",
      ">30/90, d1=0.010, d2=0.016 g=0.006, a1=100, a2=100\n",
      ">31/90, d1=0.014, d2=0.014 g=0.006, a1=100, a2=100\n",
      ">32/90, d1=0.012, d2=0.014 g=0.006, a1=100, a2=100\n",
      ">33/90, d1=0.009, d2=0.014 g=0.005, a1=100, a2=100\n",
      ">34/90, d1=0.029, d2=0.014 g=0.006, a1=100, a2=100\n",
      ">35/90, d1=0.012, d2=0.014 g=0.005, a1=100, a2=100\n",
      ">36/90, d1=0.005, d2=0.013 g=0.004, a1=100, a2=100\n",
      ">37/90, d1=0.012, d2=0.012 g=0.005, a1=100, a2=100\n",
      ">38/90, d1=0.015, d2=0.011 g=0.004, a1=100, a2=100\n",
      ">39/90, d1=0.011, d2=0.011 g=0.005, a1=100, a2=100\n",
      ">40/90, d1=0.008, d2=0.010 g=0.004, a1=100, a2=100\n",
      ">41/90, d1=0.017, d2=0.010 g=0.004, a1=100, a2=100\n",
      ">42/90, d1=0.007, d2=0.010 g=0.003, a1=100, a2=100\n",
      ">43/90, d1=0.029, d2=0.010 g=0.003, a1=100, a2=100\n",
      ">44/90, d1=0.007, d2=0.010 g=0.003, a1=100, a2=100\n",
      ">45/90, d1=0.006, d2=0.010 g=0.002, a1=100, a2=100\n",
      ">46/90, d1=0.001, d2=0.009 g=0.003, a1=100, a2=100\n",
      ">47/90, d1=0.011, d2=0.009 g=0.003, a1=100, a2=100\n",
      ">48/90, d1=0.008, d2=0.008 g=0.002, a1=100, a2=100\n",
      ">49/90, d1=0.004, d2=0.009 g=0.003, a1=100, a2=100\n",
      ">50/90, d1=0.011, d2=0.008 g=0.003, a1=100, a2=100\n",
      ">51/90, d1=0.013, d2=0.008 g=0.002, a1=100, a2=100\n",
      ">52/90, d1=0.011, d2=0.008 g=0.002, a1=100, a2=100\n",
      ">53/90, d1=0.012, d2=0.008 g=0.002, a1=100, a2=100\n",
      ">54/90, d1=0.011, d2=0.009 g=0.002, a1=100, a2=100\n",
      ">55/90, d1=0.012, d2=0.007 g=0.002, a1=100, a2=100\n",
      ">56/90, d1=0.003, d2=0.008 g=0.002, a1=100, a2=100\n",
      ">57/90, d1=0.004, d2=0.008 g=0.002, a1=100, a2=100\n",
      ">58/90, d1=0.010, d2=0.008 g=0.002, a1=100, a2=100\n",
      ">59/90, d1=0.012, d2=0.008 g=0.001, a1=100, a2=100\n",
      ">60/90, d1=0.006, d2=0.007 g=0.002, a1=100, a2=100\n",
      ">61/90, d1=0.003, d2=0.007 g=0.001, a1=100, a2=100\n",
      ">62/90, d1=0.010, d2=0.007 g=0.001, a1=100, a2=100\n",
      ">63/90, d1=0.006, d2=0.007 g=0.002, a1=100, a2=100\n",
      ">64/90, d1=0.004, d2=0.006 g=0.001, a1=100, a2=100\n",
      ">65/90, d1=0.005, d2=0.007 g=0.001, a1=100, a2=100\n",
      ">66/90, d1=0.004, d2=0.005 g=0.001, a1=100, a2=100\n",
      ">67/90, d1=0.006, d2=0.006 g=0.001, a1=100, a2=100\n",
      ">68/90, d1=0.004, d2=0.006 g=0.001, a1=100, a2=100\n",
      ">69/90, d1=0.003, d2=0.006 g=0.001, a1=100, a2=100\n",
      ">70/90, d1=0.002, d2=0.005 g=0.001, a1=100, a2=100\n",
      ">71/90, d1=0.011, d2=0.006 g=0.001, a1=100, a2=100\n",
      ">72/90, d1=0.013, d2=0.005 g=0.001, a1=100, a2=100\n",
      ">73/90, d1=0.016, d2=0.006 g=0.001, a1=100, a2=100\n",
      ">74/90, d1=0.006, d2=0.006 g=0.001, a1=100, a2=100\n",
      ">75/90, d1=0.003, d2=0.005 g=0.001, a1=100, a2=100\n",
      ">76/90, d1=0.013, d2=0.006 g=0.001, a1=100, a2=100\n",
      ">77/90, d1=0.006, d2=0.006 g=0.001, a1=100, a2=100\n",
      ">78/90, d1=0.003, d2=0.005 g=0.001, a1=100, a2=100\n",
      ">79/90, d1=0.003, d2=0.006 g=0.001, a1=100, a2=100\n",
      ">80/90, d1=0.002, d2=0.005 g=0.001, a1=100, a2=100\n",
      ">81/90, d1=0.005, d2=0.005 g=0.001, a1=100, a2=100\n",
      ">82/90, d1=0.001, d2=0.005 g=0.001, a1=100, a2=100\n",
      ">83/90, d1=0.008, d2=0.004 g=0.001, a1=100, a2=100\n",
      ">84/90, d1=0.007, d2=0.004 g=0.001, a1=100, a2=100\n",
      ">85/90, d1=0.002, d2=0.004 g=0.001, a1=100, a2=100\n",
      ">86/90, d1=0.003, d2=0.004 g=0.001, a1=100, a2=100\n",
      ">87/90, d1=0.005, d2=0.004 g=0.001, a1=100, a2=100\n",
      ">88/90, d1=0.002, d2=0.005 g=0.001, a1=100, a2=100\n",
      ">89/90, d1=0.008, d2=0.004 g=0.001, a1=100, a2=100\n",
      ">90/90, d1=0.002, d2=0.004 g=0.001, a1=100, a2=100\n",
      "finished training\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Training of existing model file:\n",
    "May not always want to run this cell\n",
    "\"\"\"\n",
    "\n",
    "n_epochs = 10\n",
    "n_batch = 10\n",
    "train(model, discriminator, gan_model, dataset, latent_dim, n_epochs, n_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "getting the prediction directly from generator\n",
    "functionally the same as prediction instance\n",
    "\"\"\"\n",
    "\n",
    "test = generate_fake_samples(generator, latent_dim, n_samples = 1)[0]\n",
    "# convert floats from ranges 0:1 to 0:255, so they can be blackness values in an image\n",
    "test = predictionInstance*255 \n",
    "# print(xout) # this is diagnostic\n",
    "# np.shape(xout) # this is diagnostic\n",
    "flatXOut = xout.flatten()  \n",
    "# print(len(flatXOut)) # should be 40,000 # this is diagnostic\n",
    "arr_2d = np.reshape(flatXOut, (200, 200))\n",
    "# convert float array to ints\n",
    "array_int = abs(np.array(arr_2d, dtype='int')) \n",
    "# print(np.shape(array_int)) # this is diagnostic\n",
    "# array_int # this is diagnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n\"\"\"\\ngetting the prediction into something useful\\n\"\"\"\\n\\n# convert floats from ranges 0:1 to 0:255, so they can be blackness values in an image\\nxout = predictionInstance*255 \\n# print(xout) # this is diagnostic\\n# np.shape(xout) # this is diagnostic\\nflatXOut = xout.flatten()  \\n# print(len(flatXOut)) # should be 40,000 # this is diagnostic\\narr_2d = np.reshape(flatXOut, (200, 200))\\n# convert float array to ints\\narray_int = abs(np.array(arr_2d, dtype=\\'int\\')) \\n# print(np.shape(array_int)) # this is diagnostic\\n# array_int # this is diagnostic\\n\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "source": [
    "'''\n",
    "\"\"\"\n",
    "getting the prediction into something useful\n",
    "\"\"\"\n",
    "\n",
    "# convert floats from ranges 0:1 to 0:255, so they can be blackness values in an image\n",
    "xout = predictionInstance*255 \n",
    "# print(xout) # this is diagnostic\n",
    "# np.shape(xout) # this is diagnostic\n",
    "flatXOut = xout.flatten()  \n",
    "# print(len(flatXOut)) # should be 40,000 # this is diagnostic\n",
    "arr_2d = np.reshape(flatXOut, (200, 200))\n",
    "# convert float array to ints\n",
    "array_int = abs(np.array(arr_2d, dtype='int')) \n",
    "# print(np.shape(array_int)) # this is diagnostic\n",
    "# array_int # this is diagnostic\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\ndiagnostic check of the output image\\n\\n# code:\\nprint(\"Format: {0}\\nSize: {1}\\nMode: {2}\".format(img.format, \\n    img.size, img.mode)) \\n# end code\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 121
    }
   ],
   "source": [
    "\"\"\"\n",
    "draw the image of the output array\n",
    "\"\"\"\n",
    "\n",
    "img = Image.fromarray(array_int)\n",
    "img.show()\n",
    "\n",
    "\"\"\"\n",
    "diagnostic check of the output image\n",
    "\n",
    "# code:\n",
    "print(\"Format: {0}\\nSize: {1}\\nMode: {2}\".format(img.format, \n",
    "    img.size, img.mode)) \n",
    "# end code\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "convert the image file to a recognisable and portable format\n",
    "write out the image file to somewhere in the local machine\n",
    "\"\"\"\n",
    "\n",
    "imgRGB = img.convert(mode=\"RGB\")\n",
    "imgRGB.save(\"C:\\\\Users\\\\DataSci\\\\Desktop\\\\DS_Testing\\\\warGAN\\\\output\\\\dreamParamTest.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd0fd02e15c5e8f5ee6cdee280f4db237d56a650e119945c60bf91993c8f57ebb6a",
   "display_name": "Python 3.8.5 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}