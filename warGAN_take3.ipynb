{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python385jvsc74a57bd0fd02e15c5e8f5ee6cdee280f4db237d56a650e119945c60bf91993c8f57ebb6a",
      "display_name": "Python 3.8.5 64-bit (conda)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    },
    "colab": {
      "name": "warGAN_take3.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvkgrkaeN3Fr"
      },
      "source": [
        "# GAN IMPLEMENTATION FROM COMMUNITY INQ28 MODELS\n",
        "- Code Author: Jack MacCormick\n",
        "- Instagram: argelpaints: https://www.instagram.com/argelpaints/\n",
        "- Done in partnership with 28MAG: https://28-mag.com/\n",
        "\n",
        "**GAN Training and Development Code:**\n",
        "\n",
        "This project is the use of GAN style Machine Learning algorithms to generate new images, based off the works of the Warhammer INQ28 community. These images are the dreamings of an abhorent AI system, who's task is to understand \"what is INQ28\" it knows not the world, it's surroundings, only those offered to it, and the endless void"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjdWA9soN_Nl",
        "outputId": "cfa6ed3e-6a58-4d75-874f-ff3e226efdf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2XzmLphN3Fs"
      },
      "source": [
        "# import necessary packages\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import pylab\n",
        "import h5py\n",
        "\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "from numpy import expand_dims\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy.random import random\n",
        "from numpy.random import randint\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from tqdm import tqdm \n",
        "from IPython import display "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H61lp3EwPM9U"
      },
      "source": [
        "learningRate = 0.00015\n",
        "n_epochs = 50 # number of \"generations\"\n",
        "n_batch = 20 # no. of images in each batch"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0tR1JKEN3Ft"
      },
      "source": [
        "\"\"\"\n",
        "define the standalone discriminator model\n",
        "key value is the learning rate lr\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def define_discriminator(in_shape=(200,200,1)):\n",
        "\t# weight initialization\n",
        "\tinit = 'uniform'\n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        "\t# downsample to 100x100\n",
        "\tmodel.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, input_shape=in_shape))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# downsample to 50x50\n",
        "\tmodel.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# classifier\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# compile model\n",
        "\topt = Adam(lr=0.0001, beta_1=0.5)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFYvDa97N3Ft"
      },
      "source": [
        "def define_generator(latent_dim):\n",
        "\t# weight initialization\n",
        "\tinit = 'uniform'\n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        "\t# foundation for 50x50 image\n",
        "\tn_nodes = 256 * 50 * 50\n",
        "\tmodel.add(Dense(n_nodes, kernel_initializer=init, input_dim=latent_dim))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Reshape((50, 50, 256)))\n",
        "\t# upsample to 100x100\n",
        "\tmodel.add(Conv2DTranspose(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# upsample to 200x200\n",
        "\tmodel.add(Conv2DTranspose(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# output 28x28x1\n",
        "\tmodel.add(Conv2D(1, (7,7), activation='tanh', padding='same', kernel_initializer=init))\n",
        "\treturn model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbo8AaESN3Fu"
      },
      "source": [
        "# define the combined generator and discriminator model, for updating the generator\n",
        "def define_gan(generator, discriminator):\n",
        "\t# make weights in the discriminator not trainable\n",
        "\tdiscriminator.trainable = False\n",
        "\t# connect them\n",
        "\tmodel = Sequential()\n",
        "\t# add generator\n",
        "\tmodel.add(generator)\n",
        "\t# add the discriminator\n",
        "\tmodel.add(discriminator)\n",
        "\t# compile model\n",
        "\topt = Adam(lr=learningRate, beta_1=0.7) # lr=00015 seems to be the ideal value for training\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "\treturn model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDcW9TnyN3Fu"
      },
      "source": [
        "# default values of standardised images\n",
        "preferred_width = 200\n",
        "preferred_height = 200"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFcQwtFrPkiA"
      },
      "source": [
        "pathSource = '/content/drive/MyDrive/BnWDrive'\n",
        "dir_list = os.listdir(pathSource)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xl3i_0GAOZJ_"
      },
      "source": [
        "images = []\n",
        "# for image in pathSource, convert them to BnW, save that to pathDest, then add standardised version to images[]\n",
        "for image in dir_list:\n",
        "    img = Image.open(pathSource+\"/\"+image)\n",
        "    imgArray = np.array(img) # int array of pixels\n",
        "    imgArray = imgArray.astype(float)/255 # standardise values to be 0:255\n",
        "    images.append(imgArray)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAzoYSfVN3Fw",
        "outputId": "e2303199-b51e-4d43-c837-bb435a05434e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# setting a param for proportion of data to keep for testing\n",
        "testingSize = int(len(dir_list)/5)\n",
        "\n",
        "X_testing = np.array(images[0:testingSize])\n",
        "X_training = np.array(images[testingSize:len(images)])\n",
        "\n",
        "\"\"\"\n",
        "# this is all diagnostic checks to ensure data is passed correctly to training and testing splits\n",
        "\n",
        "# code:\n",
        "print(np.shape(X_testing)) \n",
        "print(X_testing[1]) # checking it's correctly put something into the testing variable\n",
        "print(np.shape(X_training))\n",
        "# end code\n",
        "\"\"\"\n",
        "\n",
        "()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV21XCFMN3Fw"
      },
      "source": [
        "# select real samples\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "\t# choose random instances\n",
        "\tix = randint(0, dataset.shape[0], n_samples)\n",
        "\t# select images\n",
        "\tX = dataset[ix]\n",
        "\t# generate class labels\n",
        "\ty = ones((n_samples, 1))\n",
        "\treturn X, y"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmw5tCJbN3Fw"
      },
      "source": [
        "# generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "\t# generate points in the latent space\n",
        "\tx_input = np.random.uniform(low=0.0, high=1.0, size=(latent_dim, n_samples))\n",
        "\t# reshape into a batch of inputs for the network\n",
        "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
        "\treturn x_input"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGzrSa3GN3Fx"
      },
      "source": [
        "# use the generator to generate n fake examples, with class labels\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "\t# generate points in latent space\n",
        "\tx_input = abs(generate_latent_points(latent_dim, n_samples))\n",
        "\t# predict outputs\n",
        "\tX = generator.predict(x_input)\n",
        "\t# create class labels\n",
        "\ty = zeros((n_samples, 1))\n",
        "\treturn X, y"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOzLxk6-N3Fx"
      },
      "source": [
        "\"\"\"\n",
        "trains the generator and discriminator parts of the GAN\n",
        "saves the net model to a .h5 file\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "'''\n",
        "# done in train+draw function\n",
        "\n",
        "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs, n_batch):\n",
        "\t# calculate the number of batches per epoch\n",
        "\tbat_per_epo = int(dataset.shape[0] / n_batch)\n",
        "\t# calculate the total iterations based on batch and epoch\n",
        "\tn_steps = bat_per_epo * n_epochs\n",
        "\t# calculate the number of samples in half a batch\n",
        "\thalf_batch = int(n_batch / 2)\n",
        "\t# prepare lists for storing stats each iteration\n",
        "\td1_hist, d2_hist, g_hist, a1_hist, a2_hist = list(), list(), list(), list(), list()\n",
        "\t# manually enumerate epochs\n",
        "\tfor i in range(n_steps):\n",
        "\t\t# get randomly selected 'real' samples\n",
        "\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "\t\t# update discriminator model weights\n",
        "\t\td_loss1, d_acc1 = d_model.train_on_batch(X_real, y_real)\n",
        "\t\t# generate 'fake' examples\n",
        "\t\tX_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "\t\t# update discriminator model weights\n",
        "\t\td_loss2, d_acc2 = d_model.train_on_batch(X_fake, y_fake)\n",
        "\t\t# prepare points in latent space as input for the generator\n",
        "\t\tX_gan = generate_latent_points(latent_dim, n_batch)\n",
        "\t\t# create inverted labels for the fake samples\n",
        "\t\ty_gan = ones((n_batch, 1))\n",
        "\t\t# update the generator via the discriminator's error\n",
        "\t\tg_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "\t\t# summarize loss on this batch\n",
        "\t\tprint('>%d/%d, d1=%.3f, d2=%.3f g=%.3f, a1=%d, a2=%d' %\n",
        "\t\t\t(i+1, n_steps, d_loss1, d_loss2, g_loss, int(100*d_acc1), int(100*d_acc2)))\n",
        "\t\t# record history\n",
        "\t\td1_hist.append(d_loss1)\n",
        "\t\td2_hist.append(d_loss2)\n",
        "\t\tg_hist.append(g_loss)\n",
        "\t\ta1_hist.append(d_acc1)\n",
        "\t\ta2_hist.append(d_acc2)\n",
        "\t\tif (i%10==0): # save frequency, this should really be a smart value\n",
        "\t\t\tg_model.save('WARgenerator.h5')\t\t\n",
        "\tprint(\"finished training\")\n",
        "\t# this is the generator that can be called externally\n",
        "\tg_model.save('WARgenerator.h5') \n",
        "\n",
        "  '''\n",
        "  \n",
        "\t\"\"\"\n",
        "\tSave is also embed this within the loop every so many itterations\n",
        "\tso something is saved/retained if user needs to abort while long training processes are occuring or if something fails, if the kernel or local machine crashes or if local machine looses power\n",
        "\t\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE2TwB57N3Fx"
      },
      "source": [
        "\"\"\"\n",
        "set up the data into something the GAN can use in training\n",
        "\"\"\"\n",
        "\n",
        "X_train=np.reshape(X_training,(X_training.shape[0], X_training.shape[1],X_training.shape[2],1))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "i7NTO10VN3Fy"
      },
      "source": [
        "\"\"\"\n",
        "set up for training and training call\n",
        "this can take some time depending on number of epochs\n",
        "recommend running on a GPU\n",
        "\"\"\"\n",
        "\n",
        "# training params\n",
        "latent_dim = 50 # size of the latent space\n",
        "# training above 50 generations, results stabilise, and no change is noticable\n",
        "\n",
        "# create the discriminator\n",
        "discriminator = define_discriminator()\n",
        "# create the generator\n",
        "generator = define_generator(latent_dim)\n",
        "# create the gan\n",
        "gan_model = define_gan(generator, discriminator)\n",
        "# load image data\n",
        "dataset = X_train\n",
        "\n",
        "# train model\n",
        "# train(generator, discriminator, gan_model, dataset, latent_dim, n_epochs, n_batch)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNtZAHU3N3Fy"
      },
      "source": [
        "\"\"\"\n",
        "getting the model to draw something,\n",
        "this can be done seperately, if put in another file\n",
        "\"\"\"\n",
        "\n",
        "''' currently doing in func\n",
        "\n",
        "model = load_model('WARgenerator.h5', compile = False)\n",
        "# generate images\n",
        "latent_points = generate_latent_points(latent_dim, 1)\n",
        " # has quite the think about it\n",
        "predictionInstance = model.predict(latent_points)\n",
        "print(\"done thinking\")\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKqyPOEFN3Fy"
      },
      "source": [
        "\"\"\"\n",
        "Training of existing model file:\n",
        "May not always want to run this cell\n",
        "\"\"\"\n",
        "\n",
        "'''\n",
        "n_epochs = 10\n",
        "train(model, discriminator, gan_model, dataset, latent_dim, n_epochs, n_batch)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zxxqpY4N3Fz"
      },
      "source": [
        "\"\"\"\n",
        "getting the prediction directly from generator\n",
        "functionally the same as prediction instance\n",
        "\"\"\"\n",
        "\n",
        "''' currently doing in func\n",
        "\n",
        "xout = generate_fake_samples(generator, latent_dim, n_samples = 1)[0]\n",
        "# predictionInstance = model.predict(latent_points)\n",
        "# convert floats from ranges 0:1 to 0:255, so they can be blackness values in an image\n",
        "xout = predictionInstance*255 \n",
        "# print(xout) # this is diagnostic\n",
        "# np.shape(xout) # this is diagnostic\n",
        "flatXOut = xout.flatten()  \n",
        "# print(len(flatXOut)) # should be 40,000 # this is diagnostic\n",
        "arr_2d = np.reshape(flatXOut, (200, 200))\n",
        "# convert float array to ints\n",
        "array_int = abs(np.array(arr_2d, dtype='int')) \n",
        "print(np.shape(array_int)) # this is diagnostic\n",
        "array_int # this is diagnostic\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8MAwV3CN3Fz"
      },
      "source": [
        "\"\"\"\n",
        "draw the image of the output array\n",
        "\"\"\"\n",
        "\n",
        "''' currently doing in func\n",
        "img = Image.fromarray(array_int.astype(np.uint8))\n",
        "\n",
        "'''\n",
        "\n",
        "\"\"\"\n",
        "diagnostic check of the output image\n",
        "\n",
        "# code:\n",
        "print(\"Format: {0}\\nSize: {1}\\nMode: {2}\".format(img.format, \n",
        "    img.size, img.mode)) \n",
        "# end code\n",
        "\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu834qShN3Fz"
      },
      "source": [
        "\"\"\"\n",
        "convert the image file to a recognisable and portable format\n",
        "write out the image file to somewhere in the local machine\n",
        "\"\"\"\n",
        "\n",
        "''' currently doing in func\n",
        "\n",
        "pathOut = '/content/drive/MyDrive/BnWOut/batch = 40'\n",
        "imgRGB = img.convert(mode=\"RGB\")\n",
        "imgRGB.save(pathOut+\"/dreamParamTest1.jpg\")\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vs4ar1aGN3F0"
      },
      "source": [
        "\"\"\"\n",
        "image generation function\n",
        "can be called solo, compounds all of the post processing into one function, but designed for use in loops\n",
        "does away with all the diagnostics\n",
        "\"\"\"\n",
        "\n",
        "def getInstanceImage(pathOut, imgName):\n",
        "    model = load_model('WARgenerator.h5', compile = False)\n",
        "    # generate images\n",
        "    latent_points = generate_latent_points(latent_dim, 1)\n",
        "    # has quite the think about it\n",
        "    predictionInstance = model.predict(latent_points)\n",
        "\n",
        "    # xout = generate_fake_samples(generator, latent_dim, n_samples = 1)[0] # this is being shadowed, I think\n",
        "    # convert floats from ranges 0:1 to 0:255, so they can be blackness values in an image\n",
        "    xout = predictionInstance*255 \n",
        "    flatXOut = xout.flatten()  \n",
        "    arr_2d = np.reshape(flatXOut, (200, 200))\n",
        "    # convert float array to ints\n",
        "    array_int = abs(np.array(arr_2d, dtype='int'))\n",
        "    img = Image.fromarray(array_int.astype(np.uint8))\n",
        "    \n",
        "    # saving image\n",
        "    imgRGB = img.convert(mode=\"RGB\")\n",
        "    imgRGB.save(pathOut+\"/\"+imgName+\".jpg\")\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Nz_LaICN-Gk"
      },
      "source": [
        "\"\"\"\n",
        "trains the generator and discriminator parts of the GAN\n",
        "saves the net model to a .h5 file\n",
        "\"\"\"\n",
        "\n",
        "def trainAndSave(g_model, d_model, gan_model, dataset, latent_dim, n_epochs, n_batch, filePath, imagePrefix):\n",
        "    # calculate the number of batches per epoch\n",
        "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
        "    # calculate the total iterations based on batch and epoch\n",
        "    n_steps = bat_per_epo * n_epochs\n",
        "    # calculate the number of samples in half a batch\n",
        "    half_batch = int(n_batch / 2)\n",
        "    # prepare lists for storing stats each iteration\n",
        "    d1_hist, d2_hist, g_hist, a1_hist, a2_hist = list(), list(), list(), list(), list()\n",
        "    # manually enumerate epochs\n",
        "    for i in range(n_steps):\n",
        "      # get randomly selected 'real' samples\n",
        "      X_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "      # update discriminator model weights\n",
        "      d_loss1, d_acc1 = d_model.train_on_batch(X_real, y_real)\n",
        "      # generate 'fake' examples\n",
        "      X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "      # update discriminator model weights\n",
        "      d_loss2, d_acc2 = d_model.train_on_batch(X_fake, y_fake)\n",
        "      # prepare points in latent space as input for the generator\n",
        "      X_gan = generate_latent_points(latent_dim, n_batch)\n",
        "      # create inverted labels for the fake samples\n",
        "      y_gan = ones((n_batch, 1))\n",
        "      # update the generator via the discriminator's error\n",
        "      g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "      # summarize loss on this batch\n",
        "      print('>%d/%d, d1=%.3f, d2=%.3f g=%.3f, a1=%d, a2=%d' %\n",
        "\t\t\t(i+1, n_steps, d_loss1, d_loss2, g_loss, int(100*d_acc1), int(100*d_acc2)))\n",
        "      # record history\n",
        "      d1_hist.append(d_loss1)\n",
        "      d2_hist.append(d_loss2)\n",
        "      g_hist.append(g_loss)\n",
        "      a1_hist.append(d_acc1)\n",
        "      a2_hist.append(d_acc2)\n",
        "      if (i%10==0): # save frequency, this should really be a smart value\n",
        "        g_model.save('WARgenerator.h5')\n",
        "        getInstanceImage(filePath, (imagePrefix+\"_step_\"+str(i)))\n",
        "    print(\"finished training\")\n",
        "\t  # this is the generator that can be called externally\n",
        "    g_model.save('WARgenerator.h5')\n",
        " \n",
        " "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_LEAgtxOg0t",
        "outputId": "f17f85ef-1abf-4a95-b817-2b13e7204974",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "n_epochs = 80\n",
        "trainAndSave(generator, discriminator, gan_model, dataset, latent_dim, n_epochs, n_batch, '/content/drive/MyDrive/BnWOut/timeSeries2', 'batchTrain')\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">1/560, d1=0.675, d2=0.766 g=0.680, a1=89, a2=0\n",
            ">2/560, d1=0.634, d2=0.780 g=0.688, a1=100, a2=0\n",
            ">3/560, d1=0.603, d2=0.805 g=0.690, a1=100, a2=0\n",
            ">4/560, d1=0.599, d2=0.827 g=0.694, a1=100, a2=0\n",
            ">5/560, d1=0.625, d2=0.808 g=0.717, a1=100, a2=0\n",
            ">6/560, d1=0.672, d2=0.745 g=0.763, a1=80, a2=0\n",
            ">7/560, d1=0.704, d2=0.722 g=0.758, a1=40, a2=0\n",
            ">8/560, d1=0.721, d2=0.684 g=0.775, a1=0, a2=100\n",
            ">9/560, d1=0.725, d2=0.643 g=0.792, a1=10, a2=100\n",
            ">10/560, d1=0.739, d2=0.627 g=0.802, a1=10, a2=100\n",
            ">11/560, d1=0.723, d2=0.615 g=0.813, a1=10, a2=100\n",
            ">12/560, d1=0.727, d2=0.607 g=0.815, a1=10, a2=100\n",
            ">13/560, d1=0.736, d2=0.606 g=0.814, a1=0, a2=100\n",
            ">14/560, d1=0.717, d2=0.605 g=0.816, a1=30, a2=100\n",
            ">15/560, d1=0.703, d2=0.604 g=0.827, a1=40, a2=100\n",
            ">16/560, d1=0.706, d2=0.603 g=0.839, a1=40, a2=100\n",
            ">17/560, d1=0.698, d2=0.607 g=0.840, a1=60, a2=100\n",
            ">18/560, d1=0.699, d2=0.618 g=0.829, a1=50, a2=100\n",
            ">19/560, d1=0.687, d2=0.646 g=0.816, a1=50, a2=100\n",
            ">20/560, d1=0.678, d2=0.667 g=0.791, a1=50, a2=100\n",
            ">21/560, d1=0.706, d2=0.686 g=0.775, a1=30, a2=69\n",
            ">22/560, d1=0.678, d2=0.711 g=0.753, a1=60, a2=0\n",
            ">23/560, d1=0.678, d2=0.730 g=0.727, a1=69, a2=0\n",
            ">24/560, d1=0.679, d2=0.727 g=0.725, a1=50, a2=0\n",
            ">25/560, d1=0.674, d2=0.726 g=0.726, a1=69, a2=0\n",
            ">26/560, d1=0.651, d2=0.719 g=0.739, a1=89, a2=0\n",
            ">27/560, d1=0.580, d2=0.737 g=0.721, a1=100, a2=0\n",
            ">28/560, d1=0.511, d2=0.847 g=0.647, a1=100, a2=0\n",
            ">29/560, d1=0.464, d2=1.033 g=0.588, a1=100, a2=0\n",
            ">30/560, d1=0.540, d2=1.047 g=0.650, a1=100, a2=0\n",
            ">31/560, d1=0.619, d2=0.862 g=0.722, a1=89, a2=0\n",
            ">32/560, d1=0.708, d2=0.733 g=0.778, a1=10, a2=0\n",
            ">33/560, d1=0.736, d2=0.660 g=0.790, a1=0, a2=100\n",
            ">34/560, d1=0.761, d2=0.648 g=0.788, a1=0, a2=100\n",
            ">35/560, d1=0.726, d2=0.648 g=0.779, a1=10, a2=100\n",
            ">36/560, d1=0.741, d2=0.646 g=0.774, a1=0, a2=100\n",
            ">37/560, d1=0.741, d2=0.651 g=0.762, a1=10, a2=100\n",
            ">38/560, d1=0.717, d2=0.660 g=0.752, a1=20, a2=100\n",
            ">39/560, d1=0.718, d2=0.666 g=0.746, a1=20, a2=100\n",
            ">40/560, d1=0.705, d2=0.669 g=0.744, a1=40, a2=100\n",
            ">41/560, d1=0.725, d2=0.673 g=0.740, a1=20, a2=100\n",
            ">42/560, d1=0.721, d2=0.677 g=0.736, a1=30, a2=100\n",
            ">43/560, d1=0.719, d2=0.678 g=0.734, a1=10, a2=100\n",
            ">44/560, d1=0.715, d2=0.679 g=0.734, a1=20, a2=100\n",
            ">45/560, d1=0.707, d2=0.679 g=0.735, a1=40, a2=100\n",
            ">46/560, d1=0.717, d2=0.680 g=0.734, a1=10, a2=100\n",
            ">47/560, d1=0.731, d2=0.682 g=0.734, a1=0, a2=100\n",
            ">48/560, d1=0.725, d2=0.683 g=0.733, a1=10, a2=100\n",
            ">49/560, d1=0.716, d2=0.682 g=0.736, a1=20, a2=100\n",
            ">50/560, d1=0.716, d2=0.681 g=0.741, a1=0, a2=100\n",
            ">51/560, d1=0.712, d2=0.677 g=0.750, a1=30, a2=100\n",
            ">52/560, d1=0.725, d2=0.675 g=0.747, a1=10, a2=100\n",
            ">53/560, d1=0.707, d2=0.676 g=0.748, a1=20, a2=100\n",
            ">54/560, d1=0.705, d2=0.675 g=0.750, a1=20, a2=100\n",
            ">55/560, d1=0.702, d2=0.676 g=0.756, a1=20, a2=100\n",
            ">56/560, d1=0.704, d2=0.673 g=0.762, a1=30, a2=100\n",
            ">57/560, d1=0.710, d2=0.675 g=0.755, a1=20, a2=100\n",
            ">58/560, d1=0.701, d2=0.683 g=0.750, a1=50, a2=100\n",
            ">59/560, d1=0.690, d2=0.685 g=0.746, a1=69, a2=89\n",
            ">60/560, d1=0.678, d2=0.695 g=0.743, a1=60, a2=20\n",
            ">61/560, d1=0.689, d2=0.694 g=0.745, a1=50, a2=60\n",
            ">62/560, d1=0.689, d2=0.686 g=0.750, a1=60, a2=89\n",
            ">63/560, d1=0.692, d2=0.676 g=0.759, a1=50, a2=100\n",
            ">64/560, d1=0.694, d2=0.669 g=0.764, a1=40, a2=100\n",
            ">65/560, d1=0.698, d2=0.664 g=0.768, a1=40, a2=100\n",
            ">66/560, d1=0.701, d2=0.663 g=0.764, a1=10, a2=100\n",
            ">67/560, d1=0.686, d2=0.674 g=0.749, a1=60, a2=100\n",
            ">68/560, d1=0.666, d2=0.683 g=0.743, a1=89, a2=100\n",
            ">69/560, d1=0.680, d2=0.694 g=0.735, a1=80, a2=50\n",
            ">70/560, d1=0.667, d2=0.707 g=0.726, a1=89, a2=0\n",
            ">71/560, d1=0.660, d2=0.720 g=0.718, a1=80, a2=0\n",
            ">72/560, d1=0.647, d2=0.736 g=0.701, a1=100, a2=0\n",
            ">73/560, d1=0.650, d2=0.746 g=0.700, a1=89, a2=0\n",
            ">74/560, d1=0.655, d2=0.754 g=0.700, a1=89, a2=0\n",
            ">75/560, d1=0.639, d2=0.760 g=0.698, a1=89, a2=0\n",
            ">76/560, d1=0.605, d2=0.769 g=0.694, a1=100, a2=0\n",
            ">77/560, d1=0.595, d2=0.772 g=0.702, a1=100, a2=0\n",
            ">78/560, d1=0.574, d2=0.774 g=0.715, a1=100, a2=0\n",
            ">79/560, d1=0.585, d2=0.791 g=0.706, a1=100, a2=0\n",
            ">80/560, d1=0.602, d2=0.813 g=0.704, a1=100, a2=0\n",
            ">81/560, d1=0.634, d2=0.813 g=0.703, a1=89, a2=0\n",
            ">82/560, d1=0.693, d2=0.755 g=0.725, a1=50, a2=0\n",
            ">83/560, d1=0.718, d2=0.710 g=0.740, a1=10, a2=0\n",
            ">84/560, d1=0.723, d2=0.678 g=0.757, a1=10, a2=100\n",
            ">85/560, d1=0.726, d2=0.661 g=0.767, a1=20, a2=100\n",
            ">86/560, d1=0.736, d2=0.648 g=0.777, a1=0, a2=100\n",
            ">87/560, d1=0.736, d2=0.641 g=0.784, a1=10, a2=100\n",
            ">88/560, d1=0.728, d2=0.632 g=0.794, a1=0, a2=100\n",
            ">89/560, d1=0.720, d2=0.622 g=0.804, a1=10, a2=100\n",
            ">90/560, d1=0.733, d2=0.617 g=0.801, a1=20, a2=100\n",
            ">91/560, d1=0.705, d2=0.619 g=0.805, a1=60, a2=100\n",
            ">92/560, d1=0.725, d2=0.619 g=0.807, a1=20, a2=100\n",
            ">93/560, d1=0.723, d2=0.624 g=0.805, a1=10, a2=100\n",
            ">94/560, d1=0.719, d2=0.629 g=0.797, a1=30, a2=100\n",
            ">95/560, d1=0.725, d2=0.638 g=0.785, a1=20, a2=100\n",
            ">96/560, d1=0.677, d2=0.644 g=0.784, a1=69, a2=100\n",
            ">97/560, d1=0.701, d2=0.649 g=0.775, a1=50, a2=100\n",
            ">98/560, d1=0.719, d2=0.654 g=0.770, a1=40, a2=100\n",
            ">99/560, d1=0.731, d2=0.668 g=0.751, a1=30, a2=100\n",
            ">100/560, d1=0.708, d2=0.676 g=0.740, a1=50, a2=100\n",
            ">101/560, d1=0.678, d2=0.685 g=0.732, a1=80, a2=89\n",
            ">102/560, d1=0.673, d2=0.695 g=0.724, a1=60, a2=40\n",
            ">103/560, d1=0.691, d2=0.705 g=0.713, a1=60, a2=0\n",
            ">104/560, d1=0.682, d2=0.715 g=0.701, a1=69, a2=0\n",
            ">105/560, d1=0.649, d2=0.728 g=0.688, a1=80, a2=0\n",
            ">106/560, d1=0.706, d2=0.747 g=0.673, a1=30, a2=0\n",
            ">107/560, d1=0.714, d2=0.757 g=0.666, a1=40, a2=0\n",
            ">108/560, d1=0.713, d2=0.753 g=0.675, a1=30, a2=0\n",
            ">109/560, d1=0.697, d2=0.759 g=0.674, a1=40, a2=0\n",
            ">110/560, d1=0.673, d2=0.754 g=0.678, a1=80, a2=0\n",
            ">111/560, d1=0.662, d2=0.755 g=0.679, a1=80, a2=0\n",
            ">112/560, d1=0.624, d2=0.777 g=0.675, a1=100, a2=0\n",
            ">113/560, d1=0.608, d2=0.817 g=0.665, a1=89, a2=0\n",
            ">114/560, d1=0.523, d2=0.862 g=0.670, a1=100, a2=0\n",
            ">115/560, d1=0.500, d2=0.889 g=0.731, a1=100, a2=0\n",
            ">116/560, d1=0.564, d2=0.871 g=0.765, a1=100, a2=0\n",
            ">117/560, d1=0.662, d2=0.770 g=0.802, a1=60, a2=0\n",
            ">118/560, d1=0.736, d2=0.716 g=0.767, a1=0, a2=0\n",
            ">119/560, d1=0.732, d2=0.656 g=0.780, a1=0, a2=100\n",
            ">120/560, d1=0.731, d2=0.639 g=0.786, a1=10, a2=100\n",
            ">121/560, d1=0.744, d2=0.633 g=0.784, a1=0, a2=100\n",
            ">122/560, d1=0.717, d2=0.632 g=0.787, a1=10, a2=100\n",
            ">123/560, d1=0.728, d2=0.630 g=0.786, a1=20, a2=100\n",
            ">124/560, d1=0.722, d2=0.632 g=0.783, a1=30, a2=100\n",
            ">125/560, d1=0.693, d2=0.634 g=0.784, a1=20, a2=100\n",
            ">126/560, d1=0.717, d2=0.637 g=0.780, a1=20, a2=100\n",
            ">127/560, d1=0.713, d2=0.641 g=0.774, a1=40, a2=100\n",
            ">128/560, d1=0.689, d2=0.647 g=0.768, a1=60, a2=100\n",
            ">129/560, d1=0.690, d2=0.655 g=0.763, a1=50, a2=100\n",
            ">130/560, d1=0.704, d2=0.664 g=0.756, a1=40, a2=100\n",
            ">131/560, d1=0.705, d2=0.673 g=0.747, a1=30, a2=100\n",
            ">132/560, d1=0.647, d2=0.676 g=0.744, a1=80, a2=100\n",
            ">133/560, d1=0.716, d2=0.681 g=0.735, a1=30, a2=100\n",
            ">134/560, d1=0.699, d2=0.691 g=0.729, a1=60, a2=60\n",
            ">135/560, d1=0.696, d2=0.695 g=0.720, a1=50, a2=40\n",
            ">136/560, d1=0.720, d2=0.701 g=0.716, a1=20, a2=0\n",
            ">137/560, d1=0.675, d2=0.712 g=0.708, a1=80, a2=0\n",
            ">138/560, d1=0.680, d2=0.716 g=0.702, a1=80, a2=0\n",
            ">139/560, d1=0.695, d2=0.720 g=0.705, a1=50, a2=0\n",
            ">140/560, d1=0.668, d2=0.712 g=0.717, a1=60, a2=0\n",
            ">141/560, d1=0.656, d2=0.699 g=0.750, a1=100, a2=0\n",
            ">142/560, d1=0.635, d2=0.674 g=0.799, a1=100, a2=100\n",
            ">143/560, d1=0.570, d2=0.665 g=0.835, a1=100, a2=100\n",
            ">144/560, d1=0.545, d2=0.727 g=0.820, a1=100, a2=0\n",
            ">145/560, d1=0.526, d2=0.880 g=0.713, a1=80, a2=0\n",
            ">146/560, d1=0.527, d2=1.096 g=0.679, a1=100, a2=0\n",
            ">147/560, d1=0.759, d2=0.841 g=0.841, a1=40, a2=0\n",
            ">148/560, d1=0.760, d2=0.607 g=0.897, a1=0, a2=100\n",
            ">149/560, d1=0.783, d2=0.582 g=0.858, a1=0, a2=100\n",
            ">150/560, d1=0.747, d2=0.586 g=0.842, a1=0, a2=100\n",
            ">151/560, d1=0.742, d2=0.592 g=0.834, a1=20, a2=100\n",
            ">152/560, d1=0.711, d2=0.593 g=0.832, a1=30, a2=100\n",
            ">153/560, d1=0.728, d2=0.593 g=0.830, a1=10, a2=100\n",
            ">154/560, d1=0.707, d2=0.594 g=0.834, a1=30, a2=100\n",
            ">155/560, d1=0.701, d2=0.595 g=0.830, a1=50, a2=100\n",
            ">156/560, d1=0.692, d2=0.597 g=0.824, a1=40, a2=100\n",
            ">157/560, d1=0.698, d2=0.608 g=0.813, a1=50, a2=100\n",
            ">158/560, d1=0.655, d2=0.624 g=0.806, a1=69, a2=100\n",
            ">159/560, d1=0.665, d2=0.646 g=0.786, a1=80, a2=100\n",
            ">160/560, d1=0.655, d2=0.667 g=0.766, a1=60, a2=100\n",
            ">161/560, d1=0.650, d2=0.690 g=0.753, a1=69, a2=69\n",
            ">162/560, d1=0.699, d2=0.682 g=0.759, a1=60, a2=100\n",
            ">163/560, d1=0.700, d2=0.686 g=0.752, a1=60, a2=80\n",
            ">164/560, d1=0.712, d2=0.708 g=0.725, a1=40, a2=0\n",
            ">165/560, d1=0.671, d2=0.709 g=0.710, a1=60, a2=0\n",
            ">166/560, d1=0.671, d2=0.711 g=0.710, a1=60, a2=0\n",
            ">167/560, d1=0.685, d2=0.711 g=0.711, a1=50, a2=0\n",
            ">168/560, d1=0.698, d2=0.713 g=0.708, a1=50, a2=0\n",
            ">169/560, d1=0.680, d2=0.710 g=0.710, a1=60, a2=0\n",
            ">170/560, d1=0.705, d2=0.709 g=0.715, a1=40, a2=0\n",
            ">171/560, d1=0.679, d2=0.704 g=0.720, a1=50, a2=0\n",
            ">172/560, d1=0.654, d2=0.699 g=0.728, a1=80, a2=0\n",
            ">173/560, d1=0.675, d2=0.696 g=0.734, a1=60, a2=0\n",
            ">174/560, d1=0.650, d2=0.697 g=0.739, a1=69, a2=0\n",
            ">175/560, d1=0.689, d2=0.701 g=0.737, a1=40, a2=0\n",
            ">176/560, d1=0.644, d2=0.705 g=0.739, a1=89, a2=0\n",
            ">177/560, d1=0.665, d2=0.715 g=0.746, a1=100, a2=0\n",
            ">178/560, d1=0.650, d2=0.724 g=0.737, a1=89, a2=0\n",
            ">179/560, d1=0.629, d2=0.748 g=0.710, a1=100, a2=0\n",
            ">180/560, d1=0.628, d2=0.796 g=0.680, a1=100, a2=0\n",
            ">181/560, d1=0.592, d2=0.814 g=0.664, a1=100, a2=0\n",
            ">182/560, d1=0.559, d2=0.833 g=0.676, a1=100, a2=0\n",
            ">183/560, d1=0.570, d2=0.833 g=0.694, a1=100, a2=0\n",
            ">184/560, d1=0.562, d2=0.838 g=0.713, a1=100, a2=0\n",
            ">185/560, d1=0.611, d2=0.842 g=0.703, a1=100, a2=0\n",
            ">186/560, d1=0.580, d2=0.789 g=0.732, a1=89, a2=0\n",
            ">187/560, d1=0.644, d2=0.755 g=0.737, a1=89, a2=0\n",
            ">188/560, d1=0.652, d2=0.740 g=0.744, a1=80, a2=0\n",
            ">189/560, d1=0.640, d2=0.722 g=0.750, a1=89, a2=0\n",
            ">190/560, d1=0.678, d2=0.711 g=0.755, a1=60, a2=0\n",
            ">191/560, d1=0.670, d2=0.704 g=0.763, a1=69, a2=0\n",
            ">192/560, d1=0.667, d2=0.700 g=0.769, a1=80, a2=0\n",
            ">193/560, d1=0.664, d2=0.700 g=0.775, a1=80, a2=0\n",
            ">194/560, d1=0.680, d2=0.708 g=0.770, a1=60, a2=0\n",
            ">195/560, d1=0.685, d2=0.718 g=0.755, a1=69, a2=0\n",
            ">196/560, d1=0.710, d2=0.716 g=0.746, a1=40, a2=0\n",
            ">197/560, d1=0.715, d2=0.708 g=0.747, a1=30, a2=0\n",
            ">198/560, d1=0.711, d2=0.700 g=0.745, a1=10, a2=0\n",
            ">199/560, d1=0.729, d2=0.696 g=0.744, a1=30, a2=40\n",
            ">200/560, d1=0.741, d2=0.692 g=0.742, a1=10, a2=60\n",
            ">201/560, d1=0.740, d2=0.695 g=0.738, a1=20, a2=30\n",
            ">202/560, d1=0.721, d2=0.691 g=0.739, a1=20, a2=80\n",
            ">203/560, d1=0.718, d2=0.686 g=0.741, a1=30, a2=100\n",
            ">204/560, d1=0.722, d2=0.684 g=0.743, a1=20, a2=100\n",
            ">205/560, d1=0.746, d2=0.681 g=0.742, a1=0, a2=100\n",
            ">206/560, d1=0.735, d2=0.681 g=0.743, a1=0, a2=100\n",
            ">207/560, d1=0.712, d2=0.678 g=0.747, a1=30, a2=100\n",
            ">208/560, d1=0.723, d2=0.676 g=0.747, a1=10, a2=100\n",
            ">209/560, d1=0.744, d2=0.677 g=0.745, a1=10, a2=100\n",
            ">210/560, d1=0.753, d2=0.678 g=0.743, a1=0, a2=100\n",
            ">211/560, d1=0.739, d2=0.680 g=0.742, a1=10, a2=100\n",
            ">212/560, d1=0.729, d2=0.679 g=0.745, a1=10, a2=100\n",
            ">213/560, d1=0.737, d2=0.673 g=0.752, a1=0, a2=100\n",
            ">214/560, d1=0.719, d2=0.668 g=0.758, a1=30, a2=100\n",
            ">215/560, d1=0.728, d2=0.664 g=0.763, a1=20, a2=100\n",
            ">216/560, d1=0.726, d2=0.660 g=0.771, a1=20, a2=100\n",
            ">217/560, d1=0.722, d2=0.656 g=0.774, a1=20, a2=100\n",
            ">218/560, d1=0.737, d2=0.655 g=0.776, a1=10, a2=100\n",
            ">219/560, d1=0.745, d2=0.656 g=0.773, a1=0, a2=100\n",
            ">220/560, d1=0.740, d2=0.658 g=0.772, a1=0, a2=100\n",
            ">221/560, d1=0.702, d2=0.656 g=0.778, a1=20, a2=100\n",
            ">222/560, d1=0.721, d2=0.653 g=0.780, a1=20, a2=100\n",
            ">223/560, d1=0.713, d2=0.650 g=0.784, a1=30, a2=100\n",
            ">224/560, d1=0.718, d2=0.646 g=0.788, a1=20, a2=100\n",
            ">225/560, d1=0.721, d2=0.647 g=0.790, a1=30, a2=100\n",
            ">226/560, d1=0.721, d2=0.644 g=0.793, a1=30, a2=100\n",
            ">227/560, d1=0.706, d2=0.639 g=0.796, a1=40, a2=100\n",
            ">228/560, d1=0.729, d2=0.639 g=0.794, a1=10, a2=100\n",
            ">229/560, d1=0.716, d2=0.642 g=0.792, a1=20, a2=100\n",
            ">230/560, d1=0.725, d2=0.642 g=0.788, a1=20, a2=100\n",
            ">231/560, d1=0.720, d2=0.644 g=0.785, a1=20, a2=100\n",
            ">232/560, d1=0.702, d2=0.648 g=0.783, a1=40, a2=100\n",
            ">233/560, d1=0.729, d2=0.648 g=0.778, a1=20, a2=100\n",
            ">234/560, d1=0.736, d2=0.651 g=0.776, a1=10, a2=100\n",
            ">235/560, d1=0.709, d2=0.651 g=0.777, a1=30, a2=100\n",
            ">236/560, d1=0.725, d2=0.649 g=0.778, a1=20, a2=100\n",
            ">237/560, d1=0.702, d2=0.648 g=0.778, a1=40, a2=100\n",
            ">238/560, d1=0.728, d2=0.649 g=0.774, a1=20, a2=100\n",
            ">239/560, d1=0.717, d2=0.653 g=0.773, a1=30, a2=100\n",
            ">240/560, d1=0.722, d2=0.656 g=0.768, a1=20, a2=100\n",
            ">241/560, d1=0.712, d2=0.660 g=0.764, a1=30, a2=100\n",
            ">242/560, d1=0.700, d2=0.668 g=0.757, a1=30, a2=100\n",
            ">243/560, d1=0.718, d2=0.688 g=0.735, a1=10, a2=100\n",
            ">244/560, d1=0.696, d2=0.702 g=0.755, a1=40, a2=0\n",
            ">245/560, d1=0.695, d2=0.732 g=0.704, a1=50, a2=0\n",
            ">246/560, d1=0.681, d2=0.751 g=0.692, a1=60, a2=0\n",
            ">247/560, d1=0.663, d2=0.783 g=0.693, a1=100, a2=0\n",
            ">248/560, d1=0.670, d2=0.763 g=0.742, a1=89, a2=0\n",
            ">249/560, d1=0.614, d2=0.742 g=0.712, a1=100, a2=0\n",
            ">250/560, d1=0.603, d2=0.736 g=0.717, a1=100, a2=0\n",
            ">251/560, d1=0.597, d2=0.743 g=0.729, a1=100, a2=0\n",
            ">252/560, d1=0.589, d2=0.750 g=0.735, a1=100, a2=0\n",
            ">253/560, d1=0.596, d2=0.756 g=0.740, a1=100, a2=0\n",
            ">254/560, d1=0.598, d2=0.741 g=0.760, a1=100, a2=0\n",
            ">255/560, d1=0.614, d2=0.750 g=0.747, a1=89, a2=0\n",
            ">256/560, d1=0.636, d2=0.749 g=0.760, a1=69, a2=0\n",
            ">257/560, d1=0.692, d2=0.700 g=0.782, a1=40, a2=20\n",
            ">258/560, d1=0.736, d2=0.681 g=0.783, a1=0, a2=100\n",
            ">259/560, d1=0.709, d2=0.666 g=0.785, a1=30, a2=100\n",
            ">260/560, d1=0.737, d2=0.661 g=0.782, a1=20, a2=100\n",
            ">261/560, d1=0.695, d2=0.652 g=0.788, a1=40, a2=100\n",
            ">262/560, d1=0.730, d2=0.645 g=0.793, a1=10, a2=100\n",
            ">263/560, d1=0.750, d2=0.645 g=0.787, a1=10, a2=100\n",
            ">264/560, d1=0.733, d2=0.648 g=0.781, a1=20, a2=100\n",
            ">265/560, d1=0.726, d2=0.650 g=0.777, a1=10, a2=100\n",
            ">266/560, d1=0.676, d2=0.649 g=0.773, a1=50, a2=100\n",
            ">267/560, d1=0.716, d2=0.655 g=0.764, a1=30, a2=100\n",
            ">268/560, d1=0.701, d2=0.662 g=0.756, a1=30, a2=100\n",
            ">269/560, d1=0.723, d2=0.670 g=0.746, a1=20, a2=100\n",
            ">270/560, d1=0.678, d2=0.677 g=0.741, a1=60, a2=100\n",
            ">271/560, d1=0.685, d2=0.679 g=0.739, a1=50, a2=100\n",
            ">272/560, d1=0.721, d2=0.680 g=0.734, a1=30, a2=100\n",
            ">273/560, d1=0.708, d2=0.683 g=0.730, a1=40, a2=100\n",
            ">274/560, d1=0.689, d2=0.686 g=0.726, a1=50, a2=100\n",
            ">275/560, d1=0.675, d2=0.689 g=0.725, a1=60, a2=100\n",
            ">276/560, d1=0.698, d2=0.690 g=0.725, a1=50, a2=80\n",
            ">277/560, d1=0.719, d2=0.690 g=0.725, a1=30, a2=89\n",
            ">278/560, d1=0.681, d2=0.691 g=0.724, a1=69, a2=80\n",
            ">279/560, d1=0.717, d2=0.688 g=0.723, a1=40, a2=100\n",
            ">280/560, d1=0.685, d2=0.692 g=0.724, a1=40, a2=69\n",
            ">281/560, d1=0.697, d2=0.693 g=0.722, a1=40, a2=40\n",
            ">282/560, d1=0.647, d2=0.696 g=0.719, a1=80, a2=20\n",
            ">283/560, d1=0.683, d2=0.704 g=0.713, a1=50, a2=0\n",
            ">284/560, d1=0.726, d2=0.719 g=0.710, a1=10, a2=0\n",
            ">285/560, d1=0.678, d2=0.728 g=0.708, a1=80, a2=0\n",
            ">286/560, d1=0.683, d2=0.737 g=0.724, a1=80, a2=0\n",
            ">287/560, d1=0.699, d2=0.759 g=0.693, a1=40, a2=0\n",
            ">288/560, d1=0.695, d2=0.780 g=0.708, a1=40, a2=0\n",
            ">289/560, d1=0.675, d2=0.769 g=0.721, a1=80, a2=0\n",
            ">290/560, d1=0.640, d2=0.730 g=0.745, a1=100, a2=0\n",
            ">291/560, d1=0.631, d2=0.740 g=0.708, a1=100, a2=0\n",
            ">292/560, d1=0.636, d2=0.738 g=0.727, a1=100, a2=0\n",
            ">293/560, d1=0.623, d2=0.720 g=0.742, a1=100, a2=0\n",
            ">294/560, d1=0.611, d2=0.704 g=0.752, a1=100, a2=0\n",
            ">295/560, d1=0.603, d2=0.714 g=0.760, a1=100, a2=0\n",
            ">296/560, d1=0.567, d2=0.747 g=0.774, a1=100, a2=0\n",
            ">297/560, d1=0.609, d2=0.768 g=0.781, a1=89, a2=0\n",
            ">298/560, d1=0.645, d2=0.760 g=0.806, a1=69, a2=0\n",
            ">299/560, d1=0.734, d2=0.665 g=0.843, a1=20, a2=100\n",
            ">300/560, d1=0.762, d2=0.625 g=0.839, a1=0, a2=100\n",
            ">301/560, d1=0.745, d2=0.601 g=0.852, a1=10, a2=100\n",
            ">302/560, d1=0.741, d2=0.582 g=0.867, a1=0, a2=100\n",
            ">303/560, d1=0.732, d2=0.569 g=0.874, a1=20, a2=100\n",
            ">304/560, d1=0.713, d2=0.565 g=0.882, a1=30, a2=100\n",
            ">305/560, d1=0.725, d2=0.563 g=0.884, a1=30, a2=100\n",
            ">306/560, d1=0.696, d2=0.563 g=0.890, a1=40, a2=100\n",
            ">307/560, d1=0.696, d2=0.563 g=0.895, a1=60, a2=100\n",
            ">308/560, d1=0.656, d2=0.561 g=0.902, a1=80, a2=100\n",
            ">309/560, d1=0.664, d2=0.570 g=0.900, a1=69, a2=100\n",
            ">310/560, d1=0.654, d2=0.584 g=0.886, a1=69, a2=100\n",
            ">311/560, d1=0.695, d2=0.606 g=0.858, a1=40, a2=100\n",
            ">312/560, d1=0.687, d2=0.635 g=0.823, a1=60, a2=100\n",
            ">313/560, d1=0.651, d2=0.656 g=0.796, a1=69, a2=100\n",
            ">314/560, d1=0.659, d2=0.692 g=0.763, a1=60, a2=50\n",
            ">315/560, d1=0.691, d2=0.712 g=0.732, a1=50, a2=0\n",
            ">316/560, d1=0.686, d2=0.742 g=0.705, a1=60, a2=0\n",
            ">317/560, d1=0.676, d2=0.762 g=0.691, a1=40, a2=0\n",
            ">318/560, d1=0.678, d2=0.771 g=0.673, a1=50, a2=0\n",
            ">319/560, d1=0.671, d2=0.772 g=0.670, a1=50, a2=0\n",
            ">320/560, d1=0.676, d2=0.770 g=0.676, a1=60, a2=0\n",
            ">321/560, d1=0.664, d2=0.759 g=0.686, a1=50, a2=0\n",
            ">322/560, d1=0.693, d2=0.747 g=0.708, a1=40, a2=0\n",
            ">323/560, d1=0.693, d2=0.718 g=0.765, a1=50, a2=0\n",
            ">324/560, d1=0.700, d2=0.660 g=0.870, a1=40, a2=100\n",
            ">325/560, d1=0.695, d2=0.606 g=0.949, a1=60, a2=100\n",
            ">326/560, d1=0.648, d2=0.670 g=0.838, a1=80, a2=100\n",
            ">327/560, d1=0.575, d2=0.969 g=0.683, a1=80, a2=0\n",
            ">328/560, d1=0.486, d2=1.062 g=0.752, a1=100, a2=0\n",
            ">329/560, d1=0.557, d2=0.840 g=0.843, a1=100, a2=0\n",
            ">330/560, d1=0.679, d2=0.707 g=0.824, a1=60, a2=0\n",
            ">331/560, d1=0.708, d2=0.653 g=0.809, a1=30, a2=100\n",
            ">332/560, d1=0.689, d2=0.631 g=0.813, a1=50, a2=100\n",
            ">333/560, d1=0.703, d2=0.619 g=0.823, a1=30, a2=100\n",
            ">334/560, d1=0.723, d2=0.615 g=0.821, a1=10, a2=100\n",
            ">335/560, d1=0.687, d2=0.619 g=0.814, a1=50, a2=100\n",
            ">336/560, d1=0.671, d2=0.620 g=0.812, a1=60, a2=100\n",
            ">337/560, d1=0.677, d2=0.628 g=0.808, a1=69, a2=100\n",
            ">338/560, d1=0.687, d2=0.637 g=0.792, a1=60, a2=100\n",
            ">339/560, d1=0.665, d2=0.652 g=0.779, a1=60, a2=100\n",
            ">340/560, d1=0.676, d2=0.667 g=0.767, a1=69, a2=100\n",
            ">341/560, d1=0.671, d2=0.681 g=0.761, a1=69, a2=100\n",
            ">342/560, d1=0.647, d2=0.686 g=0.754, a1=80, a2=89\n",
            ">343/560, d1=0.653, d2=0.691 g=0.753, a1=69, a2=69\n",
            ">344/560, d1=0.623, d2=0.691 g=0.760, a1=89, a2=69\n",
            ">345/560, d1=0.638, d2=0.688 g=0.760, a1=89, a2=69\n",
            ">346/560, d1=0.675, d2=0.690 g=0.762, a1=69, a2=80\n",
            ">347/560, d1=0.695, d2=0.689 g=0.758, a1=40, a2=80\n",
            ">348/560, d1=0.711, d2=0.690 g=0.754, a1=40, a2=89\n",
            ">349/560, d1=0.711, d2=0.690 g=0.755, a1=30, a2=100\n",
            ">350/560, d1=0.701, d2=0.692 g=0.753, a1=50, a2=80\n",
            ">351/560, d1=0.665, d2=0.693 g=0.752, a1=80, a2=20\n",
            ">352/560, d1=0.674, d2=0.696 g=0.750, a1=80, a2=10\n",
            ">353/560, d1=0.663, d2=0.703 g=0.744, a1=69, a2=0\n",
            ">354/560, d1=0.636, d2=0.716 g=0.729, a1=100, a2=0\n",
            ">355/560, d1=0.628, d2=0.733 g=0.719, a1=89, a2=0\n",
            ">356/560, d1=0.630, d2=0.762 g=0.712, a1=89, a2=0\n",
            ">357/560, d1=0.641, d2=0.792 g=0.669, a1=89, a2=0\n",
            ">358/560, d1=0.639, d2=0.819 g=0.658, a1=80, a2=0\n",
            ">359/560, d1=0.596, d2=0.836 g=0.664, a1=100, a2=0\n",
            ">360/560, d1=0.624, d2=0.832 g=0.681, a1=89, a2=0\n",
            ">361/560, d1=0.677, d2=0.814 g=0.683, a1=60, a2=0\n",
            ">362/560, d1=0.649, d2=0.792 g=0.705, a1=80, a2=0\n",
            ">363/560, d1=0.648, d2=0.760 g=0.718, a1=89, a2=0\n",
            ">364/560, d1=0.652, d2=0.750 g=0.717, a1=80, a2=0\n",
            ">365/560, d1=0.650, d2=0.747 g=0.716, a1=89, a2=0\n",
            ">366/560, d1=0.679, d2=0.738 g=0.720, a1=69, a2=0\n",
            ">367/560, d1=0.675, d2=0.736 g=0.722, a1=89, a2=0\n",
            ">368/560, d1=0.708, d2=0.724 g=0.729, a1=20, a2=0\n",
            ">369/560, d1=0.683, d2=0.707 g=0.743, a1=60, a2=0\n",
            ">370/560, d1=0.700, d2=0.690 g=0.757, a1=40, a2=100\n",
            ">371/560, d1=0.710, d2=0.683 g=0.759, a1=20, a2=100\n",
            ">372/560, d1=0.723, d2=0.678 g=0.763, a1=10, a2=100\n",
            ">373/560, d1=0.709, d2=0.669 g=0.773, a1=40, a2=100\n",
            ">374/560, d1=0.710, d2=0.653 g=0.792, a1=30, a2=100\n",
            ">375/560, d1=0.719, d2=0.644 g=0.796, a1=20, a2=100\n",
            ">376/560, d1=0.706, d2=0.639 g=0.802, a1=40, a2=100\n",
            ">377/560, d1=0.720, d2=0.630 g=0.818, a1=20, a2=100\n",
            ">378/560, d1=0.719, d2=0.623 g=0.827, a1=40, a2=100\n",
            ">379/560, d1=0.726, d2=0.620 g=0.831, a1=30, a2=100\n",
            ">380/560, d1=0.742, d2=0.622 g=0.832, a1=10, a2=100\n",
            ">381/560, d1=0.712, d2=0.624 g=0.831, a1=40, a2=100\n",
            ">382/560, d1=0.711, d2=0.627 g=0.831, a1=50, a2=100\n",
            ">383/560, d1=0.662, d2=0.617 g=0.856, a1=69, a2=100\n",
            ">384/560, d1=0.690, d2=0.610 g=0.866, a1=50, a2=100\n",
            ">385/560, d1=0.699, d2=0.610 g=0.869, a1=40, a2=100\n",
            ">386/560, d1=0.762, d2=0.624 g=0.842, a1=20, a2=100\n",
            ">387/560, d1=0.690, d2=0.635 g=0.836, a1=60, a2=100\n",
            ">388/560, d1=0.665, d2=0.635 g=0.845, a1=60, a2=100\n",
            ">389/560, d1=0.661, d2=0.625 g=0.870, a1=69, a2=100\n",
            ">390/560, d1=0.688, d2=0.619 g=0.877, a1=50, a2=100\n",
            ">391/560, d1=0.715, d2=0.627 g=0.860, a1=40, a2=100\n",
            ">392/560, d1=0.691, d2=0.641 g=0.845, a1=69, a2=100\n",
            ">393/560, d1=0.658, d2=0.649 g=0.844, a1=80, a2=100\n",
            ">394/560, d1=0.710, d2=0.657 g=0.830, a1=40, a2=100\n",
            ">395/560, d1=0.739, d2=0.676 g=0.795, a1=30, a2=100\n",
            ">396/560, d1=0.729, d2=0.691 g=0.771, a1=50, a2=89\n",
            ">397/560, d1=0.692, d2=0.701 g=0.759, a1=60, a2=0\n",
            ">398/560, d1=0.675, d2=0.705 g=0.748, a1=80, a2=0\n",
            ">399/560, d1=0.728, d2=0.714 g=0.734, a1=40, a2=0\n",
            ">400/560, d1=0.653, d2=0.708 g=0.738, a1=80, a2=0\n",
            ">401/560, d1=0.681, d2=0.703 g=0.732, a1=50, a2=0\n",
            ">402/560, d1=0.708, d2=0.712 g=0.727, a1=60, a2=0\n",
            ">403/560, d1=0.686, d2=0.719 g=0.718, a1=50, a2=0\n",
            ">404/560, d1=0.676, d2=0.717 g=0.713, a1=60, a2=0\n",
            ">405/560, d1=0.691, d2=0.722 g=0.712, a1=40, a2=0\n",
            ">406/560, d1=0.686, d2=0.724 g=0.711, a1=50, a2=0\n",
            ">407/560, d1=0.682, d2=0.729 g=0.706, a1=50, a2=0\n",
            ">408/560, d1=0.682, d2=0.729 g=0.705, a1=69, a2=0\n",
            ">409/560, d1=0.677, d2=0.733 g=0.705, a1=80, a2=0\n",
            ">410/560, d1=0.653, d2=0.732 g=0.711, a1=100, a2=0\n",
            ">411/560, d1=0.644, d2=0.738 g=0.696, a1=89, a2=0\n",
            ">412/560, d1=0.608, d2=0.741 g=0.708, a1=100, a2=0\n",
            ">413/560, d1=0.579, d2=0.753 g=0.697, a1=100, a2=0\n",
            ">414/560, d1=0.524, d2=0.777 g=0.703, a1=100, a2=0\n",
            ">415/560, d1=0.473, d2=0.794 g=0.705, a1=89, a2=0\n",
            ">416/560, d1=0.376, d2=0.834 g=0.686, a1=100, a2=0\n",
            ">417/560, d1=0.438, d2=0.957 g=0.685, a1=100, a2=0\n",
            ">418/560, d1=0.458, d2=0.973 g=0.754, a1=100, a2=0\n",
            ">419/560, d1=0.568, d2=0.976 g=0.691, a1=100, a2=0\n",
            ">420/560, d1=0.595, d2=0.828 g=0.743, a1=89, a2=0\n",
            ">421/560, d1=0.689, d2=0.768 g=0.760, a1=50, a2=0\n",
            ">422/560, d1=0.713, d2=0.699 g=0.797, a1=40, a2=20\n",
            ">423/560, d1=0.731, d2=0.663 g=0.808, a1=10, a2=100\n",
            ">424/560, d1=0.725, d2=0.644 g=0.804, a1=10, a2=100\n",
            ">425/560, d1=0.731, d2=0.645 g=0.799, a1=30, a2=100\n",
            ">426/560, d1=0.721, d2=0.653 g=0.787, a1=20, a2=100\n",
            ">427/560, d1=0.745, d2=0.666 g=0.773, a1=0, a2=100\n",
            ">428/560, d1=0.744, d2=0.669 g=0.775, a1=20, a2=100\n",
            ">429/560, d1=0.712, d2=0.654 g=0.794, a1=40, a2=100\n",
            ">430/560, d1=0.721, d2=0.642 g=0.804, a1=20, a2=100\n",
            ">431/560, d1=0.731, d2=0.645 g=0.792, a1=10, a2=100\n",
            ">432/560, d1=0.719, d2=0.645 g=0.784, a1=30, a2=100\n",
            ">433/560, d1=0.725, d2=0.643 g=0.788, a1=40, a2=100\n",
            ">434/560, d1=0.732, d2=0.645 g=0.782, a1=20, a2=100\n",
            ">435/560, d1=0.728, d2=0.649 g=0.779, a1=30, a2=100\n",
            ">436/560, d1=0.706, d2=0.650 g=0.777, a1=40, a2=100\n",
            ">437/560, d1=0.730, d2=0.656 g=0.773, a1=50, a2=100\n",
            ">438/560, d1=0.707, d2=0.658 g=0.767, a1=30, a2=100\n",
            ">439/560, d1=0.736, d2=0.661 g=0.760, a1=10, a2=100\n",
            ">440/560, d1=0.693, d2=0.664 g=0.758, a1=50, a2=100\n",
            ">441/560, d1=0.727, d2=0.668 g=0.754, a1=20, a2=100\n",
            ">442/560, d1=0.734, d2=0.673 g=0.748, a1=20, a2=100\n",
            ">443/560, d1=0.709, d2=0.678 g=0.744, a1=40, a2=100\n",
            ">444/560, d1=0.718, d2=0.681 g=0.740, a1=20, a2=100\n",
            ">445/560, d1=0.674, d2=0.681 g=0.741, a1=69, a2=100\n",
            ">446/560, d1=0.714, d2=0.680 g=0.742, a1=40, a2=100\n",
            ">447/560, d1=0.706, d2=0.680 g=0.743, a1=50, a2=100\n",
            ">448/560, d1=0.679, d2=0.678 g=0.748, a1=60, a2=100\n",
            ">449/560, d1=0.691, d2=0.674 g=0.754, a1=40, a2=100\n",
            ">450/560, d1=0.713, d2=0.672 g=0.757, a1=30, a2=100\n",
            ">451/560, d1=0.715, d2=0.674 g=0.760, a1=10, a2=100\n",
            ">452/560, d1=0.703, d2=0.672 g=0.768, a1=30, a2=100\n",
            ">453/560, d1=0.687, d2=0.668 g=0.776, a1=69, a2=100\n",
            ">454/560, d1=0.697, d2=0.670 g=0.781, a1=50, a2=100\n",
            ">455/560, d1=0.693, d2=0.678 g=0.782, a1=40, a2=100\n",
            ">456/560, d1=0.686, d2=0.677 g=0.779, a1=50, a2=100\n",
            ">457/560, d1=0.699, d2=0.674 g=0.779, a1=30, a2=100\n",
            ">458/560, d1=0.699, d2=0.677 g=0.774, a1=20, a2=100\n",
            ">459/560, d1=0.699, d2=0.673 g=0.770, a1=40, a2=100\n",
            ">460/560, d1=0.678, d2=0.677 g=0.766, a1=60, a2=100\n",
            ">461/560, d1=0.679, d2=0.682 g=0.764, a1=69, a2=100\n",
            ">462/560, d1=0.669, d2=0.683 g=0.763, a1=69, a2=100\n",
            ">463/560, d1=0.688, d2=0.685 g=0.761, a1=69, a2=100\n",
            ">464/560, d1=0.688, d2=0.687 g=0.757, a1=50, a2=89\n",
            ">465/560, d1=0.662, d2=0.688 g=0.760, a1=69, a2=100\n",
            ">466/560, d1=0.676, d2=0.682 g=0.765, a1=60, a2=100\n",
            ">467/560, d1=0.688, d2=0.679 g=0.769, a1=40, a2=100\n",
            ">468/560, d1=0.679, d2=0.675 g=0.775, a1=60, a2=100\n",
            ">469/560, d1=0.650, d2=0.670 g=0.784, a1=80, a2=100\n",
            ">470/560, d1=0.700, d2=0.671 g=0.779, a1=50, a2=100\n",
            ">471/560, d1=0.679, d2=0.675 g=0.778, a1=60, a2=100\n",
            ">472/560, d1=0.656, d2=0.673 g=0.788, a1=60, a2=100\n",
            ">473/560, d1=0.665, d2=0.663 g=0.802, a1=80, a2=100\n",
            ">474/560, d1=0.702, d2=0.665 g=0.796, a1=40, a2=100\n",
            ">475/560, d1=0.674, d2=0.671 g=0.795, a1=80, a2=100\n",
            ">476/560, d1=0.629, d2=0.666 g=0.807, a1=69, a2=100\n",
            ">477/560, d1=0.674, d2=0.665 g=0.804, a1=60, a2=100\n",
            ">478/560, d1=0.651, d2=0.670 g=0.803, a1=60, a2=100\n",
            ">479/560, d1=0.642, d2=0.682 g=0.794, a1=60, a2=100\n",
            ">480/560, d1=0.638, d2=0.693 g=0.783, a1=60, a2=30\n",
            ">481/560, d1=0.694, d2=0.707 g=0.763, a1=40, a2=0\n",
            ">482/560, d1=0.659, d2=0.709 g=0.762, a1=50, a2=0\n",
            ">483/560, d1=0.661, d2=0.706 g=0.762, a1=69, a2=10\n",
            ">484/560, d1=0.679, d2=0.708 g=0.755, a1=69, a2=10\n",
            ">485/560, d1=0.715, d2=0.716 g=0.736, a1=40, a2=0\n",
            ">486/560, d1=0.719, d2=0.722 g=0.722, a1=30, a2=0\n",
            ">487/560, d1=0.695, d2=0.728 g=0.717, a1=50, a2=0\n",
            ">488/560, d1=0.705, d2=0.739 g=0.709, a1=50, a2=0\n",
            ">489/560, d1=0.725, d2=0.745 g=0.699, a1=20, a2=0\n",
            ">490/560, d1=0.676, d2=0.740 g=0.705, a1=40, a2=0\n",
            ">491/560, d1=0.694, d2=0.738 g=0.708, a1=50, a2=0\n",
            ">492/560, d1=0.668, d2=0.743 g=0.708, a1=69, a2=0\n",
            ">493/560, d1=0.675, d2=0.746 g=0.710, a1=80, a2=0\n",
            ">494/560, d1=0.654, d2=0.746 g=0.713, a1=80, a2=0\n",
            ">495/560, d1=0.630, d2=0.743 g=0.726, a1=80, a2=0\n",
            ">496/560, d1=0.610, d2=0.742 g=0.735, a1=80, a2=0\n",
            ">497/560, d1=0.615, d2=0.738 g=0.753, a1=100, a2=0\n",
            ">498/560, d1=0.593, d2=0.742 g=0.741, a1=89, a2=0\n",
            ">499/560, d1=0.591, d2=0.761 g=0.748, a1=89, a2=0\n",
            ">500/560, d1=0.558, d2=0.775 g=0.770, a1=100, a2=0\n",
            ">501/560, d1=0.534, d2=0.819 g=0.727, a1=100, a2=0\n",
            ">502/560, d1=0.598, d2=0.841 g=0.722, a1=89, a2=0\n",
            ">503/560, d1=0.609, d2=0.829 g=0.743, a1=80, a2=0\n",
            ">504/560, d1=0.702, d2=0.790 g=0.756, a1=40, a2=0\n",
            ">505/560, d1=0.735, d2=0.736 g=0.770, a1=20, a2=0\n",
            ">506/560, d1=0.780, d2=0.684 g=0.805, a1=10, a2=100\n",
            ">507/560, d1=0.771, d2=0.658 g=0.807, a1=0, a2=100\n",
            ">508/560, d1=0.761, d2=0.641 g=0.823, a1=20, a2=100\n",
            ">509/560, d1=0.754, d2=0.624 g=0.837, a1=10, a2=100\n",
            ">510/560, d1=0.773, d2=0.620 g=0.832, a1=0, a2=100\n",
            ">511/560, d1=0.768, d2=0.628 g=0.817, a1=10, a2=100\n",
            ">512/560, d1=0.706, d2=0.648 g=0.795, a1=30, a2=100\n",
            ">513/560, d1=0.688, d2=0.665 g=0.780, a1=60, a2=100\n",
            ">514/560, d1=0.701, d2=0.679 g=0.762, a1=60, a2=100\n",
            ">515/560, d1=0.741, d2=0.709 g=0.730, a1=20, a2=0\n",
            ">516/560, d1=0.696, d2=0.746 g=0.709, a1=50, a2=0\n",
            ">517/560, d1=0.671, d2=0.753 g=0.691, a1=69, a2=0\n",
            ">518/560, d1=0.670, d2=0.768 g=0.682, a1=69, a2=0\n",
            ">519/560, d1=0.697, d2=0.766 g=0.684, a1=40, a2=0\n",
            ">520/560, d1=0.691, d2=0.750 g=0.692, a1=40, a2=0\n",
            ">521/560, d1=0.645, d2=0.745 g=0.700, a1=100, a2=0\n",
            ">522/560, d1=0.673, d2=0.725 g=0.727, a1=80, a2=0\n",
            ">523/560, d1=0.621, d2=0.691 g=0.772, a1=100, a2=89\n",
            ">524/560, d1=0.600, d2=0.661 g=0.825, a1=100, a2=100\n",
            ">525/560, d1=0.584, d2=0.646 g=0.855, a1=100, a2=100\n",
            ">526/560, d1=0.578, d2=0.669 g=0.849, a1=89, a2=80\n",
            ">527/560, d1=0.605, d2=0.797 g=0.789, a1=89, a2=0\n",
            ">528/560, d1=0.643, d2=0.801 g=0.803, a1=60, a2=0\n",
            ">529/560, d1=0.734, d2=0.729 g=0.823, a1=20, a2=0\n",
            ">530/560, d1=0.752, d2=0.633 g=0.866, a1=20, a2=100\n",
            ">531/560, d1=0.754, d2=0.582 g=0.903, a1=20, a2=100\n",
            ">532/560, d1=0.758, d2=0.557 g=0.919, a1=20, a2=100\n",
            ">533/560, d1=0.748, d2=0.547 g=0.933, a1=10, a2=100\n",
            ">534/560, d1=0.702, d2=0.538 g=0.952, a1=60, a2=100\n",
            ">535/560, d1=0.718, d2=0.529 g=0.969, a1=40, a2=100\n",
            ">536/560, d1=0.576, d2=0.508 g=1.027, a1=100, a2=100\n",
            ">537/560, d1=0.707, d2=0.508 g=1.022, a1=30, a2=100\n",
            ">538/560, d1=0.701, d2=0.528 g=0.986, a1=50, a2=100\n",
            ">539/560, d1=0.692, d2=0.558 g=0.943, a1=60, a2=100\n",
            ">540/560, d1=0.728, d2=0.627 g=0.869, a1=40, a2=100\n",
            ">541/560, d1=0.685, d2=0.680 g=0.798, a1=80, a2=80\n",
            ">542/560, d1=0.664, d2=0.703 g=0.771, a1=60, a2=30\n",
            ">543/560, d1=0.639, d2=0.727 g=0.753, a1=60, a2=0\n",
            ">544/560, d1=0.658, d2=0.756 g=0.703, a1=60, a2=0\n",
            ">545/560, d1=0.596, d2=0.750 g=0.695, a1=80, a2=0\n",
            ">546/560, d1=0.639, d2=0.740 g=0.697, a1=69, a2=0\n",
            ">547/560, d1=0.674, d2=0.740 g=0.691, a1=40, a2=0\n",
            ">548/560, d1=0.633, d2=0.748 g=0.689, a1=89, a2=0\n",
            ">549/560, d1=0.697, d2=0.738 g=0.695, a1=40, a2=0\n",
            ">550/560, d1=0.708, d2=0.740 g=0.691, a1=40, a2=0\n",
            ">551/560, d1=0.660, d2=0.736 g=0.692, a1=69, a2=0\n",
            ">552/560, d1=0.706, d2=0.734 g=0.693, a1=30, a2=0\n",
            ">553/560, d1=0.674, d2=0.722 g=0.706, a1=50, a2=0\n",
            ">554/560, d1=0.697, d2=0.711 g=0.730, a1=40, a2=0\n",
            ">555/560, d1=0.636, d2=0.697 g=0.750, a1=100, a2=10\n",
            ">556/560, d1=0.609, d2=0.694 g=0.767, a1=100, a2=30\n",
            ">557/560, d1=0.634, d2=0.706 g=0.761, a1=100, a2=0\n",
            ">558/560, d1=0.530, d2=0.714 g=0.766, a1=100, a2=0\n",
            ">559/560, d1=0.478, d2=0.767 g=0.778, a1=100, a2=0\n",
            ">560/560, d1=0.504, d2=0.767 g=0.814, a1=100, a2=0\n",
            "finished training\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}