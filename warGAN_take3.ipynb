{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN IMPLEMENTATION ON MNIST DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pylab\n",
    "import h5py\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import random\n",
    "from numpy.random import randint\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tqdm import tqdm \n",
    "from IPython import display "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the standalone discriminator model\n",
    "def define_discriminator(in_shape=(200,200,1)):\n",
    "\t# weight initialization\n",
    "\tinit = 'uniform'\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\t# downsample to 100x100\n",
    "\tmodel.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, input_shape=in_shape))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# downsample to 50x50\n",
    "\tmodel.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# classifier\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# compile model\n",
    "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_generator(latent_dim):\n",
    "\t# weight initialization\n",
    "\tinit = 'uniform'\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\t# foundation for 50x50 image\n",
    "\tn_nodes = 256 * 50 * 50\n",
    "\tmodel.add(Dense(n_nodes, kernel_initializer=init, input_dim=latent_dim))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\tmodel.add(Reshape((50, 50, 256)))\n",
    "\t# upsample to 100x100\n",
    "\tmodel.add(Conv2DTranspose(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# upsample to 200x200\n",
    "\tmodel.add(Conv2DTranspose(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# output 28x28x1\n",
    "\tmodel.add(Conv2D(1, (7,7), activation='tanh', padding='same', kernel_initializer=init))\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(generator, discriminator):\n",
    "\t# make weights in the discriminator not trainable\n",
    "\tdiscriminator.trainable = False\n",
    "\t# connect them\n",
    "\tmodel = Sequential()\n",
    "\t# add generator\n",
    "\tmodel.add(generator)\n",
    "\t# add the discriminator\n",
    "\tmodel.add(discriminator)\n",
    "\t# compile model\n",
    "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default values of standardised images\n",
    "preferred_width = 200\n",
    "preferred_height = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to take images from and to save to (after transformation to BnW)\n",
    "pathSource = \"C:\\\\Users\\\\DataSci\\\\Desktop\\\\DS_Testing\\\\warGAN\\\\igTest\"\n",
    "pathDest = \"C:\\\\Users\\\\DataSci\\\\Desktop\\\\DS_Testing\\\\warGAN\\\\BnWImages\"\n",
    "# list all objects in pathSource\n",
    "dir_list = os.listdir(pathSource)\n",
    "\n",
    "# setting a param for proportion of data to keep for testing\n",
    "testingSize = int(len(dir_list)/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(10, 200, 200)\n[[0.4627451  0.4627451  0.4627451  ... 0.36470588 0.36470588 0.36470588]\n [0.4627451  0.4627451  0.4627451  ... 0.36470588 0.36470588 0.36470588]\n [0.46666667 0.46666667 0.46666667 ... 0.36470588 0.36470588 0.35294118]\n ...\n [0.4745098  0.47058824 0.4627451  ... 0.37647059 0.37647059 0.37647059]\n [0.46666667 0.47058824 0.45882353 ... 0.38823529 0.38039216 0.38431373]\n [0.4627451  0.47058824 0.4627451  ... 0.38431373 0.38823529 0.39215686]]\n(200, 200)\n"
     ]
    }
   ],
   "source": [
    "# create list, to contain all standardised images; values [0:1], instead of [0:255]\n",
    "images = []\n",
    "\n",
    "# for image in pathSource, convert them to BnW, save that to pathDest, then add standardised version to images[]\n",
    "for image in dir_list:\n",
    "    img = Image.open(pathSource+\"\\\\\"+image).convert('L').resize((preferred_width, preferred_height), Image.ANTIALIAS)\n",
    "    # img.show()\n",
    "    imgArray = np.array(img) # int array of pixels\n",
    "    imgArray = imgArray.astype(float)/255 # standardise values to be 0:255\n",
    "    images.append(imgArray)\n",
    "    img.save(pathDest+\"\\\\BnW\"+image, \"JPEG\")\n",
    "\n",
    "# diagnostic checks of images[]\n",
    "print(np.shape(images))\n",
    "print(images[0])\n",
    "print(np.shape(images[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2, 200, 200)\n[[0.53333333 0.53333333 0.53333333 ... 0.39607843 0.4        0.39607843]\n [0.53333333 0.53333333 0.53333333 ... 0.39607843 0.4        0.39607843]\n [0.5372549  0.5372549  0.53333333 ... 0.4        0.40392157 0.39607843]\n ...\n [0.43137255 0.41176471 0.42352941 ... 0.36470588 0.36078431 0.35686275]\n [0.41176471 0.42745098 0.42745098 ... 0.35294118 0.35294118 0.34901961]\n [0.4        0.43137255 0.41568627 ... 0.34901961 0.34901961 0.34901961]]\n(8, 200, 200)\n"
     ]
    }
   ],
   "source": [
    "X_testing = np.array(images[0:testingSize])\n",
    "X_training = np.array(images[testingSize:len(images)])\n",
    "\n",
    "print(np.shape(X_testing))\n",
    "print(X_testing[1]) # checking it's correctly put something into the testing variable\n",
    "# what we want to pass to the generator is list (X_testing[index])\n",
    "print(np.shape(X_training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\ntrain_data = tf.data.Dataset.from_tensor_slices((X_training))\\nvalid_data = tf.data.Dataset.from_tensor_slices((X_testing))\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "\"\"\"\n",
    "train_data = tf.data.Dataset.from_tensor_slices((X_training))\n",
    "valid_data = tf.data.Dataset.from_tensor_slices((X_testing))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "\t# choose random instances\n",
    "\tix = randint(0, dataset.shape[0], n_samples)\n",
    "\t# select images\n",
    "\tX = dataset[ix]\n",
    "\t# generate class labels\n",
    "\ty = ones((n_samples, 1))\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "\t# generate points in the latent space\n",
    "\tx_input = np.random.uniform(low=0.0, high=1.0, size=(latent_dim, n_samples))\n",
    "\t# reshape into a batch of inputs for the network\n",
    "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
    "\treturn x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "\t# generate points in latent space\n",
    "\tx_input = abs(generate_latent_points(latent_dim, n_samples))\n",
    "\t# predict outputs\n",
    "\tX = generator.predict(x_input)\n",
    "\t# create class labels\n",
    "\ty = zeros((n_samples, 1))\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the generator and discriminator\n",
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=10, n_batch=2):\n",
    "\t# calculate the number of batches per epoch\n",
    "\tbat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "\t# calculate the total iterations based on batch and epoch\n",
    "\tn_steps = bat_per_epo * n_epochs\n",
    "\t# calculate the number of samples in half a batch\n",
    "\thalf_batch = int(n_batch / 2)\n",
    "\t# prepare lists for storing stats each iteration\n",
    "\td1_hist, d2_hist, g_hist, a1_hist, a2_hist = list(), list(), list(), list(), list()\n",
    "\t# manually enumerate epochs\n",
    "\tfor i in range(n_steps):\n",
    "\t\t# get randomly selected 'real' samples\n",
    "\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "\t\t# update discriminator model weights\n",
    "\t\td_loss1, d_acc1 = d_model.train_on_batch(X_real, y_real)\n",
    "\t\t# generate 'fake' examples\n",
    "\t\tX_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "\t\t# update discriminator model weights\n",
    "\t\td_loss2, d_acc2 = d_model.train_on_batch(X_fake, y_fake)\n",
    "\t\t# prepare points in latent space as input for the generator\n",
    "\t\tX_gan = generate_latent_points(latent_dim, n_batch)\n",
    "\t\t# create inverted labels for the fake samples\n",
    "\t\ty_gan = ones((n_batch, 1))\n",
    "\t\t# update the generator via the discriminator's error\n",
    "\t\tg_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "\t\t# summarize loss on this batch\n",
    "\t\tprint('>%d, d1=%.3f, d2=%.3f g=%.3f, a1=%d, a2=%d' %\n",
    "\t\t\t(i+1, d_loss1, d_loss2, g_loss, int(100*d_acc1), int(100*d_acc2)))\n",
    "\t\t# record history\n",
    "\t\td1_hist.append(d_loss1)\n",
    "\t\td2_hist.append(d_loss2)\n",
    "\t\tg_hist.append(g_loss)\n",
    "\t\ta1_hist.append(d_acc1)\n",
    "\t\ta2_hist.append(d_acc2)\n",
    "\t\t\"\"\"\n",
    "\t\t# evaluate the model performance every 'epoch'\n",
    "\t\tif (i+1) % bat_per_epo == 0:\n",
    "\t\t\tsummarize_performance(i, g_model, latent_dim)\n",
    "\t\t\"\"\"\n",
    "\tprint(\"finished training\")\n",
    "\tg_model.save('WARgenerator.h5') # this is the generator that can be called externally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "set up the data into something the GAN can use in training\n",
    "\"\"\"\n",
    "\n",
    "X_train=np.reshape(X_training,(X_training.shape[0], X_training.shape[1],X_training.shape[2],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">1, d1=0.663, d2=0.680 g=0.761, a1=100, a2=100\n",
      ">2, d1=0.219, d2=1.011 g=0.491, a1=100, a2=0\n",
      ">3, d1=0.137, d2=1.767 g=0.334, a1=100, a2=0\n",
      ">4, d1=0.160, d2=1.500 g=0.539, a1=100, a2=0\n",
      ">5, d1=0.565, d2=0.962 g=0.859, a1=100, a2=0\n",
      ">6, d1=0.811, d2=0.690 g=0.978, a1=0, a2=100\n",
      ">7, d1=0.962, d2=0.762 g=0.780, a1=0, a2=0\n",
      ">8, d1=0.946, d2=0.843 g=0.638, a1=0, a2=0\n",
      ">9, d1=0.938, d2=0.888 g=0.561, a1=0, a2=0\n",
      ">10, d1=0.600, d2=1.034 g=0.474, a1=100, a2=0\n",
      ">11, d1=0.584, d2=1.300 g=0.427, a1=100, a2=0\n",
      ">12, d1=0.486, d2=1.311 g=0.414, a1=100, a2=0\n",
      ">13, d1=0.535, d2=1.227 g=0.453, a1=100, a2=0\n",
      ">14, d1=0.464, d2=1.191 g=0.438, a1=100, a2=0\n",
      ">15, d1=0.489, d2=1.191 g=0.530, a1=100, a2=0\n",
      ">16, d1=0.612, d2=0.999 g=0.636, a1=100, a2=0\n",
      ">17, d1=0.614, d2=0.991 g=0.587, a1=100, a2=0\n",
      ">18, d1=0.688, d2=0.961 g=0.578, a1=100, a2=0\n",
      ">19, d1=0.588, d2=0.979 g=0.565, a1=100, a2=0\n",
      ">20, d1=0.627, d2=0.958 g=0.597, a1=100, a2=0\n",
      ">21, d1=0.487, d2=0.974 g=0.588, a1=100, a2=0\n",
      ">22, d1=0.655, d2=0.974 g=0.646, a1=100, a2=0\n",
      ">23, d1=0.641, d2=0.895 g=0.661, a1=100, a2=0\n",
      ">24, d1=0.669, d2=0.898 g=0.659, a1=100, a2=0\n",
      ">25, d1=0.642, d2=0.867 g=0.666, a1=100, a2=0\n",
      ">26, d1=0.666, d2=0.873 g=0.689, a1=100, a2=0\n",
      ">27, d1=0.650, d2=0.853 g=0.740, a1=100, a2=0\n",
      ">28, d1=0.623, d2=0.805 g=0.721, a1=100, a2=0\n",
      ">29, d1=0.609, d2=0.855 g=0.657, a1=100, a2=0\n",
      ">30, d1=0.652, d2=0.896 g=0.707, a1=100, a2=0\n",
      ">31, d1=0.711, d2=0.840 g=0.736, a1=0, a2=0\n",
      ">32, d1=0.743, d2=0.808 g=0.695, a1=0, a2=0\n",
      ">33, d1=0.719, d2=0.775 g=0.758, a1=0, a2=0\n",
      ">34, d1=0.698, d2=0.790 g=0.719, a1=0, a2=0\n",
      ">35, d1=0.793, d2=0.810 g=0.733, a1=0, a2=0\n",
      ">36, d1=0.784, d2=0.772 g=0.735, a1=0, a2=0\n",
      ">37, d1=0.742, d2=0.725 g=0.778, a1=0, a2=0\n",
      ">38, d1=0.787, d2=0.718 g=0.766, a1=0, a2=0\n",
      ">39, d1=0.759, d2=0.722 g=0.771, a1=0, a2=0\n",
      ">40, d1=0.747, d2=0.727 g=0.798, a1=0, a2=0\n",
      "finished training\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "set up for training and training call\n",
    "this can take some time depending on number of epochs\n",
    "recommend running on a GPU\n",
    "\"\"\"\n",
    "\n",
    "# size of the latent space\n",
    "latent_dim = 50\n",
    "# create the discriminator\n",
    "discriminator = define_discriminator()\n",
    "# create the generator\n",
    "generator = define_generator(latent_dim)\n",
    "# create the gan\n",
    "gan_model = define_gan(generator, discriminator)\n",
    "# load image data\n",
    "dataset = X_train\n",
    "# train model\n",
    "train(generator, discriminator, gan_model, dataset, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "done thinking\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "getting the model to draw something,\n",
    "this can be done seperately, if put in another file\n",
    "\"\"\"\n",
    "\n",
    "model = load_model('WARgenerator.h5', compile = False)\n",
    "latent_points = generate_latent_points(latent_dim, 1)\n",
    "# generate images\n",
    "predictionInstance = model.predict(latent_points) # has quite the think about it\n",
    "print(\"done thinking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "getting the prediction into something useful\n",
    "\"\"\"\n",
    "\n",
    "xout = predictionInstance*255 # convert floats from ranges 0:1 to 0:255, so they can be blackness values in an image\n",
    "# print(xout) # this is diagnostic\n",
    "# np.shape(xout) # this is diagnostic\n",
    "\n",
    "flatXOut = xout.flatten()  \n",
    "# print(len(flatXOut)) # should be 40,000 # this is diagnostic\n",
    "arr_2d = np.reshape(flatXOut, (200, 200))\n",
    "\n",
    "array_int = abs(np.array(arr_2d, dtype='int')) # convert float array to ints\n",
    "# print(np.shape(array_int)) # this is diagnostic\n",
    "# array_int # this is diagnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw the image of the output array!!!!\n",
    "img = Image.fromarray(array_int)\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Format: None\nSize: (200, 200)\nMode: I\n"
     ]
    }
   ],
   "source": [
    "print(\"Format: {0}\\nSize: {1}\\nMode: {2}\".format(img.format, \n",
    "    img.size, img.mode)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgRGB = img.convert(mode=\"RGB\")\n",
    "imgRGB.save(\"output\\\\test.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd0fd02e15c5e8f5ee6cdee280f4db237d56a650e119945c60bf91993c8f57ebb6a",
   "display_name": "Python 3.8.5 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}