{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN IMPLEMENTATION ON MNIST DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pylab\n",
    "import h5py\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from numpy.random import normal\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tqdm import tqdm \n",
    "from IPython import display "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the standalone discriminator model\n",
    "def define_discriminator(in_shape=(200,200,1)):\n",
    "\t# weight initialization\n",
    "\tinit = 'uniform'\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\t# downsample to 100x100\n",
    "\tmodel.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, input_shape=in_shape))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# downsample to 50x50\n",
    "\tmodel.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# classifier\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# compile model\n",
    "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_generator(latent_dim):\n",
    "\t# weight initialization\n",
    "\tinit = 'uniform'\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\t# foundation for 50x50 image\n",
    "\tn_nodes = 256 * 50 * 50\n",
    "\tmodel.add(Dense(n_nodes, kernel_initializer=init, input_dim=latent_dim))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\tmodel.add(Reshape((50, 50, 256)))\n",
    "\t# upsample to 100x100\n",
    "\tmodel.add(Conv2DTranspose(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# upsample to 200x200\n",
    "\tmodel.add(Conv2DTranspose(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# output 28x28x1\n",
    "\tmodel.add(Conv2D(1, (7,7), activation='tanh', padding='same', kernel_initializer=init))\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(generator, discriminator):\n",
    "\t# make weights in the discriminator not trainable\n",
    "\tdiscriminator.trainable = False\n",
    "\t# connect them\n",
    "\tmodel = Sequential()\n",
    "\t# add generator\n",
    "\tmodel.add(generator)\n",
    "\t# add the discriminator\n",
    "\tmodel.add(discriminator)\n",
    "\t# compile model\n",
    "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default values of standardised images\n",
    "preferred_width = 200\n",
    "preferred_height = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to take images from and to save to (after transformation to BnW)\n",
    "pathSource = \"C:\\\\Users\\\\DataSci\\\\Desktop\\\\DS_Testing\\\\warGAN\\\\igTest\"\n",
    "pathDest = \"C:\\\\Users\\\\DataSci\\\\Desktop\\\\DS_Testing\\\\warGAN\\\\BnWImages\"\n",
    "# list all objects in pathSource\n",
    "dir_list = os.listdir(pathSource)\n",
    "\n",
    "# setting a param for proportion of data to keep for testing\n",
    "testingSize = int(len(dir_list)/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(10, 200, 200)\n[[0.4627451  0.4627451  0.4627451  ... 0.36470588 0.36470588 0.36470588]\n [0.4627451  0.4627451  0.4627451  ... 0.36470588 0.36470588 0.36470588]\n [0.46666667 0.46666667 0.46666667 ... 0.36470588 0.36470588 0.35294118]\n ...\n [0.4745098  0.47058824 0.4627451  ... 0.37647059 0.37647059 0.37647059]\n [0.46666667 0.47058824 0.45882353 ... 0.38823529 0.38039216 0.38431373]\n [0.4627451  0.47058824 0.4627451  ... 0.38431373 0.38823529 0.39215686]]\n(200, 200)\n"
     ]
    }
   ],
   "source": [
    "# create list, to contain all standardised images; values [0:1], instead of [0:255]\n",
    "images = []\n",
    "\n",
    "# for image in pathSource, convert them to BnW, save that to pathDest, then add standardised version to images[]\n",
    "for image in dir_list:\n",
    "    img = Image.open(pathSource+\"\\\\\"+image).convert('L').resize((preferred_width, preferred_height), Image.ANTIALIAS)\n",
    "    # img.show()\n",
    "    imgArray = np.array(img) # int array of pixels\n",
    "    imgArray = imgArray.astype(float)/255 # standardise values to be 0:255\n",
    "    images.append(imgArray)\n",
    "    img.save(pathDest+\"\\\\BnW\"+image, \"JPEG\")\n",
    "\n",
    "# diagnostic checks of images[]\n",
    "print(np.shape(images))\n",
    "print(images[0])\n",
    "print(np.shape(images[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2, 200, 200)\n[[0.53333333 0.53333333 0.53333333 ... 0.39607843 0.4        0.39607843]\n [0.53333333 0.53333333 0.53333333 ... 0.39607843 0.4        0.39607843]\n [0.5372549  0.5372549  0.53333333 ... 0.4        0.40392157 0.39607843]\n ...\n [0.43137255 0.41176471 0.42352941 ... 0.36470588 0.36078431 0.35686275]\n [0.41176471 0.42745098 0.42745098 ... 0.35294118 0.35294118 0.34901961]\n [0.4        0.43137255 0.41568627 ... 0.34901961 0.34901961 0.34901961]]\n(8, 200, 200)\n"
     ]
    }
   ],
   "source": [
    "X_testing = np.array(images[0:testingSize])\n",
    "X_training = np.array(images[testingSize:len(images)])\n",
    "\n",
    "print(np.shape(X_testing))\n",
    "print(X_testing[1]) # checking it's correctly put something into the testing variable\n",
    "# what we want to pass to the generator is list (X_testing[index])\n",
    "print(np.shape(X_training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\ntrain_data = tf.data.Dataset.from_tensor_slices((X_training))\\nvalid_data = tf.data.Dataset.from_tensor_slices((X_testing))\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "\"\"\"\n",
    "train_data = tf.data.Dataset.from_tensor_slices((X_training))\n",
    "valid_data = tf.data.Dataset.from_tensor_slices((X_testing))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "\t# choose random instances\n",
    "\tix = randint(0, dataset.shape[0], n_samples)\n",
    "\t# select images\n",
    "\tX = dataset[ix]\n",
    "\t# generate class labels\n",
    "\ty = ones((n_samples, 1))\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "\t# generate points in the latent space\n",
    "\tx_input = randn(latent_dim * n_samples)\n",
    "\t# reshape into a batch of inputs for the network\n",
    "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
    "\treturn x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "\t# generate points in latent space\n",
    "\tx_input = generate_latent_points(latent_dim, n_samples)\n",
    "\t# predict outputs\n",
    "\tX = generator.predict(x_input)\n",
    "\t# create class labels\n",
    "\ty = zeros((n_samples, 1))\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathOut = \"C:\\\\Users\\\\DataSci\\\\Desktop\\\\DS_Testing\\\\warGAN\\\\results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# currently commented out\n",
    "# generate samples and save as a plot and save the model\n",
    "def summarize_performance(step, g_model, latent_dim, n_samples=100):\n",
    "\t# prepare fake examples\n",
    "\tX, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "\t# plot images\n",
    "\tfor i in range(10 * 10):\n",
    "\t\t# define subplot\n",
    "\t\tplt.subplot(10, 10, 1 + i)\n",
    "\t\t# turn off axis\n",
    "\t\tplt.axis('off')\n",
    "\t\t# plot raw pixel data\n",
    "\t\tplt.imshow(X[i, :, :, 0], cmap='gray_r')\n",
    "\t# save plot to file\n",
    "\tplt.savefig(pathOut+\"results\\\\generated_plot_%03d.png\" % (step+1))\n",
    "\tplt.close()\n",
    "\t# save the generator model\n",
    "\tg_model.save(pathOut+\"results\\\\model_%03d.h5\" % (step+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# currently not used\n",
    "# create a line plot of loss for the gan and save to file\n",
    "def plot_history(d1_hist, d2_hist, g_hist, a1_hist, a2_hist):\n",
    "\t# plot loss\n",
    "\tplt.subplot(2, 1, 1)\n",
    "\tplt.plot(d1_hist, label='d-real')\n",
    "\tplt.plot(d2_hist, label='d-fake')\n",
    "\tplt.plot(g_hist, label='gen')\n",
    "\tplt.legend()\n",
    "\t# plot discriminator accuracy\n",
    "\tplt.subplot(2, 1, 2)\n",
    "\tplt.plot(a1_hist, label='acc-real')\n",
    "\tplt.plot(a2_hist, label='acc-fake')\n",
    "\tplt.legend()\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the generator and discriminator\n",
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=3, n_batch=2):\n",
    "\t# calculate the number of batches per epoch\n",
    "\tbat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "\t# calculate the total iterations based on batch and epoch\n",
    "\tn_steps = bat_per_epo * n_epochs\n",
    "\t# calculate the number of samples in half a batch\n",
    "\thalf_batch = int(n_batch / 2)\n",
    "\t# prepare lists for storing stats each iteration\n",
    "\td1_hist, d2_hist, g_hist, a1_hist, a2_hist = list(), list(), list(), list(), list()\n",
    "\t# manually enumerate epochs\n",
    "\tfor i in range(n_steps):\n",
    "\t\t# get randomly selected 'real' samples\n",
    "\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "\t\t# update discriminator model weights\n",
    "\t\td_loss1, d_acc1 = d_model.train_on_batch(X_real, y_real)\n",
    "\t\t# generate 'fake' examples\n",
    "\t\tX_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "\t\t# update discriminator model weights\n",
    "\t\td_loss2, d_acc2 = d_model.train_on_batch(X_fake, y_fake)\n",
    "\t\t# prepare points in latent space as input for the generator\n",
    "\t\tX_gan = generate_latent_points(latent_dim, n_batch)\n",
    "\t\t# create inverted labels for the fake samples\n",
    "\t\ty_gan = ones((n_batch, 1))\n",
    "\t\t# update the generator via the discriminator's error\n",
    "\t\tg_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "\t\t# summarize loss on this batch\n",
    "\t\tprint('>%d, d1=%.3f, d2=%.3f g=%.3f, a1=%d, a2=%d' %\n",
    "\t\t\t(i+1, d_loss1, d_loss2, g_loss, int(100*d_acc1), int(100*d_acc2)))\n",
    "\t\t# record history\n",
    "\t\td1_hist.append(d_loss1)\n",
    "\t\td2_hist.append(d_loss2)\n",
    "\t\tg_hist.append(g_loss)\n",
    "\t\ta1_hist.append(d_acc1)\n",
    "\t\ta2_hist.append(d_acc2)\n",
    "\t\t\"\"\"\n",
    "\t\t# evaluate the model performance every 'epoch'\n",
    "\t\tif (i+1) % bat_per_epo == 0:\n",
    "\t\t\tsummarize_performance(i, g_model, latent_dim)\n",
    "\t\t\"\"\"\n",
    "\tprint(\"finished training\")\n",
    "\tg_model.save('WARgenerator.h5')\n",
    "\t# plot_history(d1_hist, d2_hist, g_hist, a1_hist, a2_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.reshape(X_training,(X_training.shape[0], X_training.shape[1],X_training.shape[2],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">1, d1=0.709, d2=0.669 g=0.795, a1=0, a2=100\n",
      ">2, d1=0.444, d2=1.001 g=0.480, a1=100, a2=0\n",
      ">3, d1=0.360, d2=1.638 g=0.426, a1=100, a2=0\n",
      ">4, d1=0.445, d2=1.137 g=0.627, a1=100, a2=0\n",
      ">5, d1=0.628, d2=0.751 g=0.890, a1=100, a2=0\n",
      ">6, d1=0.760, d2=0.565 g=1.040, a1=0, a2=100\n",
      ">7, d1=0.818, d2=0.517 g=1.068, a1=0, a2=100\n",
      ">8, d1=0.867, d2=0.518 g=1.090, a1=0, a2=100\n",
      ">9, d1=0.804, d2=0.475 g=1.216, a1=0, a2=100\n",
      ">10, d1=0.756, d2=0.422 g=1.259, a1=0, a2=100\n",
      ">11, d1=0.633, d2=0.802 g=0.930, a1=100, a2=0\n",
      ">12, d1=0.642, d2=0.845 g=0.988, a1=100, a2=0\n",
      "finished training\n"
     ]
    }
   ],
   "source": [
    "# make folder for results\n",
    "# os.mkdir(\"results\")\n",
    "# size of the latent space\n",
    "latent_dim = 50\n",
    "# create the discriminator\n",
    "discriminator = define_discriminator()\n",
    "# create the generator\n",
    "generator = define_generator(latent_dim)\n",
    "# create the gan\n",
    "gan_model = define_gan(generator, discriminator)\n",
    "# load image data\n",
    "dataset = X_train\n",
    "# train model\n",
    "train(generator, discriminator, gan_model, dataset, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "done thinking\n"
     ]
    }
   ],
   "source": [
    "model = load_model('WARgenerator.h5', compile = False)\n",
    "latent_points = generate_latent_points(latent_dim, 1)\n",
    "# generate images\n",
    "X = model.predict(latent_points) # has quite the think about it\n",
    "print(\"done thinking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[[[  1.4438801]\n   [ 37.602806 ]\n   [  9.522763 ]\n   ...\n   [ 23.471489 ]\n   [ 18.717918 ]\n   [ 56.36351  ]]\n\n  [[ 91.82658  ]\n   [ 39.809456 ]\n   [149.85448  ]\n   ...\n   [ 25.009855 ]\n   [ 69.36266  ]\n   [  4.15548  ]]\n\n  [[ 11.292723 ]\n   [146.86972  ]\n   [ 29.626074 ]\n   ...\n   [118.82987  ]\n   [ 18.794285 ]\n   [ 15.455961 ]]\n\n  ...\n\n  [[ 40.059742 ]\n   [ 14.480219 ]\n   [155.69418  ]\n   ...\n   [ 27.936743 ]\n   [134.9231   ]\n   [ -2.6670744]]\n\n  [[-13.965725 ]\n   [ 98.87525  ]\n   [ 41.72844  ]\n   ...\n   [108.64189  ]\n   [ 44.08916  ]\n   [ 69.38846  ]]\n\n  [[ 60.97726  ]\n   [-20.34699  ]\n   [ 95.09836  ]\n   ...\n   [-34.840885 ]\n   [ 88.87372  ]\n   [ 13.289239 ]]]]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1, 200, 200, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# getting the prediction back out\n",
    "np.shape(X)\n",
    "xout = X*255\n",
    "print(xout) # there are negative values, thats an issue!!!\n",
    "np.shape(xout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[[  1.4438801]\n  [ 37.602806 ]\n  [  9.522763 ]\n  ...\n  [ 23.471489 ]\n  [ 18.717918 ]\n  [ 56.36351  ]]\n\n [[ 91.82658  ]\n  [ 39.809456 ]\n  [149.85448  ]\n  ...\n  [ 25.009855 ]\n  [ 69.36266  ]\n  [  4.15548  ]]\n\n [[ 11.292723 ]\n  [146.86972  ]\n  [ 29.626074 ]\n  ...\n  [118.82987  ]\n  [ 18.794285 ]\n  [ 15.455961 ]]\n\n ...\n\n [[ 40.059742 ]\n  [ 14.480219 ]\n  [155.69418  ]\n  ...\n  [ 27.936743 ]\n  [134.9231   ]\n  [  2.6670744]]\n\n [[ 13.965725 ]\n  [ 98.87525  ]\n  [ 41.72844  ]\n  ...\n  [108.64189  ]\n  [ 44.08916  ]\n  [ 69.38846  ]]\n\n [[ 60.97726  ]\n  [ 20.34699  ]\n  [ 95.09836  ]\n  ...\n  [ 34.840885 ]\n  [ 88.87372  ]\n  [ 13.289239 ]]]\n"
     ]
    }
   ],
   "source": [
    "xOut = abs(xout) # this is a very hacky way to fix negative values, probably should be a better one\n",
    "# print(xout)\n",
    "# print(xout[0][0])\n",
    "xOutImg = xOut[0]\n",
    "np.shape(xOutImg)\n",
    "print(xOutImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the result\n",
    "# plt.imshow(xOutImg) # still kills kernel\n",
    "'''\n",
    "earlier we used\n",
    "img.show() # PIL object, range 0:255\n",
    "the prediction result needs to be possibly turned back into a 200*200 array, from a 40,000 long tensor, and have the float values multipled by 255, and maybe rounded to ints\n",
    "From there, we should be able to plot the prediction\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd0fd02e15c5e8f5ee6cdee280f4db237d56a650e119945c60bf91993c8f57ebb6a",
   "display_name": "Python 3.8.5 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}