{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN IMPLEMENTATION ON MNIST DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial weâ€™ll be building a generative adversarial network (GAN) trained on the MNIST dataset.The purpose of this tutorial is to learn how to create undistinguishable images of hand-written digits using GAN. Let's start from the beginning by importing all the required libraries and by defining some hyper-parameters which is later used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "latent_size = 64\n",
    "hidden_size = 256\n",
    "image_size = 200\n",
    "num_epochs = 30\n",
    "batch_size = 16\n",
    "# default values of standardised images\n",
    "preferred_width = 200\n",
    "preferred_height = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to take images from and to save to (after transformation to BnW)\n",
    "pathSource = \"C:\\\\Users\\\\64223\\\\Documents\\\\DS_Testing\\\\warGAN\\\\igTest\"\n",
    "pathDest = \"C:\\\\Users\\\\64223\\\\Documents\\\\DS_Testing\\\\warGAN\\\\BnWImages\"\n",
    "# list all objects in pathSource\n",
    "dir_list = os.listdir(pathSource)\n",
    "\n",
    "# create list, to contain all standardised images; values [0:1], instead of [0:255]\n",
    "dataImages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image in pathSource, convert them to BnW, save that to pathDest, then add standardised version to images[]\n",
    "for image in dir_list:\n",
    "    img = Image.open(pathSource+\"\\\\\"+image).convert('L').resize((preferred_width, preferred_height Image.ANTIALIAS)\n",
    "    imgArray = np.array(img) # int array of pixels\n",
    "    imgArray = imgArray.astype(float)/255\n",
    "    dataImages.append(imgArray)\n",
    "    img.save(pathDest+\"\\\\BnW\"+image, \"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagnostic checks of images[]\n",
    "print(np.shape(dataImages))\n",
    "print(dataImages[0])\n",
    "print(np.shape(dataImages[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataImages, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "D = nn.Sequential(\n",
    "    nn.Linear(image_size, hidden_size),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Linear(hidden_size, hidden_size),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Linear(hidden_size, 1),\n",
    "    nn.Sigmoid())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator \n",
    "G = nn.Sequential(\n",
    "    nn.Linear(latent_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size, image_size),\n",
    "    nn.Tanh())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary cross entropy loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=0.0002)\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr=0.0002)\n",
    "\n",
    "def denorm(x):\n",
    "    out = (x + 1) / 2\n",
    "    return out.clamp(0, 1)\n",
    "\n",
    "def reset_grad():\n",
    "    d_optimizer.zero_grad()\n",
    "    g_optimizer.zero_grad()\n",
    "\n",
    "# Statistics to be saved\n",
    "d_losses = np.zeros(num_epochs)\n",
    "g_losses = np.zeros(num_epochs)\n",
    "real_scores = np.zeros(num_epochs)\n",
    "fake_scores = np.zeros(num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "total_step = len(data_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, _) in enumerate(data_loader):\n",
    "        images = images.view(batch_size, -1)\n",
    "        images = Variable(images)\n",
    "        # Create the labels which are later used as input for the BCE loss\n",
    "        real_labels = torch.ones(batch_size, 1)\n",
    "        real_labels = Variable(real_labels)\n",
    "        fake_labels = torch.zeros(batch_size, 1)\n",
    "        fake_labels = Variable(fake_labels)\n",
    "\n",
    "        # ================================================================== #\n",
    "        #                      Train the discriminator                       #\n",
    "        # ================================================================== #\n",
    "\n",
    "        # Compute BCE_Loss using real images where BCE_Loss(x, y): - y * log(D(x)) - (1-y) * log(1 - D(x))\n",
    "        # Second term of the loss is always zero since real_labels == 1\n",
    "        outputs = D(images)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "        real_score = outputs\n",
    "        \n",
    "        # Compute BCELoss using fake images\n",
    "        # First term of the loss is always zero since fake_labels == 0\n",
    "        z = torch.randn(batch_size, latent_size)\n",
    "        z = Variable(z)\n",
    "        fake_images = G(z)\n",
    "        outputs = D(fake_images)\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        fake_score = outputs\n",
    "        \n",
    "        # Backprop and optimize\n",
    "        # If D is trained so well, then don't update\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        reset_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        # ================================================================== #\n",
    "        #                        Train the generator                         #\n",
    "        # ================================================================== #\n",
    "\n",
    "        # Compute loss with fake images\n",
    "        z = torch.randn(batch_size, latent_size)\n",
    "        z = Variable(z)\n",
    "        fake_images = G(z)\n",
    "        outputs = D(fake_images)\n",
    "        \n",
    "        # We train G to maximize log(D(G(z)) instead of minimizing log(1-D(G(z)))\n",
    "        # For the reason, see the last paragraph of section 3. https://arxiv.org/pdf/1406.2661.pdf\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        \n",
    "        # Backprop and optimize\n",
    "        # if G is trained so well, then don't update\n",
    "        reset_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        # =================================================================== #\n",
    "        #                          Update Statistics                          #\n",
    "        # =================================================================== #\n",
    "        d_losses[epoch] = d_losses[epoch]*(i/(i+1.)) + d_loss.data*(1./(i+1.))\n",
    "        g_losses[epoch] = g_losses[epoch]*(i/(i+1.)) + g_loss.data*(1./(i+1.))\n",
    "        real_scores[epoch] = real_scores[epoch]*(i/(i+1.)) + real_score.mean().data*(1./(i+1.))\n",
    "        fake_scores[epoch] = fake_scores[epoch]*(i/(i+1.)) + fake_score.mean().data*(1./(i+1.))\n",
    "        \n",
    "        if (i+1) % 200 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}' \n",
    "                  .format(epoch, num_epochs, i+1, total_step, d_loss.data, g_loss.data, \n",
    "                          real_score.mean().data, fake_score.mean().data))\n",
    "    \n",
    "    # Save real images\n",
    "    if (epoch+1) == 1:\n",
    "        images = images.view(images.size(0), 1, 28, 28)\n",
    "        save_image(denorm(images.data), os.path.join(sample_dir, 'real_images.png'))\n",
    "    \n",
    "    # Save sampled images\n",
    "    fake_images = fake_images.view(fake_images.size(0), 1, 28, 28)\n",
    "    save_image(denorm(fake_images.data), os.path.join(sample_dir, 'fake_images-{}.png'.format(epoch+1)))\n",
    "    \n",
    "    # Save and plot Statistics\n",
    "    np.save(os.path.join(save_dir, 'd_losses.npy'), d_losses)\n",
    "    np.save(os.path.join(save_dir, 'g_losses.npy'), g_losses)\n",
    "    np.save(os.path.join(save_dir, 'fake_scores.npy'), fake_scores)\n",
    "    np.save(os.path.join(save_dir, 'real_scores.npy'), real_scores)\n",
    "    \n",
    "    plt.figure()\n",
    "    pylab.xlim(0, num_epochs + 1)\n",
    "    plt.plot(range(1, num_epochs + 1), d_losses, label='d loss')\n",
    "    plt.plot(range(1, num_epochs + 1), g_losses, label='g loss')    \n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(save_dir, 'loss.pdf'))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    pylab.xlim(0, num_epochs + 1)\n",
    "    pylab.ylim(0, 1)\n",
    "    plt.plot(range(1, num_epochs + 1), fake_scores, label='fake score')\n",
    "    plt.plot(range(1, num_epochs + 1), real_scores, label='real score')    \n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(save_dir, 'accuracy.pdf'))\n",
    "    plt.close()\n",
    "\n",
    "    # Save model at checkpoints\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        torch.save(G.state_dict(), os.path.join(save_dir, 'G--{}.ckpt'.format(epoch+1)))\n",
    "        torch.save(D.state_dict(), os.path.join(save_dir, 'D--{}.ckpt'.format(epoch+1)))\n",
    "\n",
    "# Save the model checkpoints \n",
    "torch.save(G.state_dict(), 'G.ckpt')\n",
    "torch.save(D.state_dict(), 'D.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}